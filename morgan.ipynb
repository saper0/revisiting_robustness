{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.3.\n",
      "WARNING:root:Cuda kernels could not loaded -> no CUDA support!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "from strn_and_rbstness.data import GraphDataset, split\n",
    "from strn_and_rbstness.helper.utils import accuracy\n",
    "from strn_and_rbstness.models import create_model\n",
    "from strn_and_rbstness.train import _train\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.datasets import Planetoid, Reddit\n",
    "from torch_geometric.nn import MessagePassing, DataParallel\n",
    "from torch_geometric.nn.inits import reset, uniform\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_dim, device,\n",
    "                 activation, dropout):\n",
    "        super(GCNNet, self).__init__()\n",
    "        conv = GCNConv\n",
    "\n",
    "        self.conv1 = conv(in_channels, hidden_dim)\n",
    "        self.conv2 = conv(hidden_dim, out_channels)\n",
    "\n",
    "        self.activation = F.relu if activation == 'relu' else F.elu\n",
    "        self.dropout = dropout\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = x.double()\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class DPSGD(SGD):\n",
    "\n",
    "    def __init__(self, params, noise_scale, gradient_norm_bound, lot_size,\n",
    "                 sample_size, lr=0.01):\n",
    "        super(DPSGD, self).__init__(params, lr=lr)\n",
    "\n",
    "        self.noise_scale = noise_scale\n",
    "        self.gradient_norm_bound = gradient_norm_bound\n",
    "        self.lot_size = lot_size\n",
    "        self.sample_size = sample_size\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.requires_grad:\n",
    "                    p.accumulated_grads = []\n",
    "\n",
    "    def per_sample_step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.requires_grad:\n",
    "                    per_sample_grad = p.grad.detach().clone()\n",
    "                    print(per_sample_grad)\n",
    "                    print(per_sample_grad.shape)\n",
    "                    ## Clipping gradient\n",
    "                    clip_grad_norm_(per_sample_grad,\n",
    "                                    max_norm=self.gradient_norm_bound)\n",
    "                    p.accumulated_grads.append(per_sample_grad)\n",
    "\n",
    "    def zero_accum_grad(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                p.accumulated_grads = []\n",
    "\n",
    "    def zero_sample_grad(self):\n",
    "        super(DPSGD, self).zero_grad()\n",
    "\n",
    "    def step(self, device, *args, **kwargs):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                # DP:\n",
    "                p.grad.data = torch.stack(p.accumulated_grads, dim=0).clone()\n",
    "\n",
    "                ## Adding noise and aggregating each element of the lot:\n",
    "                p.grad.data += torch.empty(p.grad.data.shape).normal_(mean=0.0, std=(self.noise_scale*self.gradient_norm_bound)).to(device)\n",
    "                p.grad.data = torch.sum(p.grad.data, dim=0) * self.sample_size / self.lot_size\n",
    "        super(DPSGD, self).step(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "data = Planetoid(\"data\", \"Cora\")[0]\n",
    "print(data)\n",
    "num_features = 1433\n",
    "num_classes = 7\n",
    "hidden_dim = 32\n",
    "activation = \"relu\"\n",
    "# default values\n",
    "noise_scale = 4 \n",
    "gradient_norm_bound = 1\n",
    "lot_size = 1\n",
    "sample_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "torch.Size([32, 1433])\n",
      "torch.Size([7])\n",
      "torch.Size([7, 32])\n",
      "Total parameters 46119\n",
      "Trainable parameters 46119\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "\n",
    "total_params = 0\n",
    "for param in list(model.parameters()):\n",
    "    nn = 1\n",
    "    for sp in list(param.size()):\n",
    "        nn = nn * sp\n",
    "    total_params += nn\n",
    "print(\"Total parameters\", total_params)\n",
    "\n",
    "model_params = filter(lambda param: param.requires_grad,\n",
    "                        model.parameters())\n",
    "trainable_params = sum([np.prod(param.size())\n",
    "                        for param in model_params])\n",
    "print(\"Trainable parameters\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9459, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "model = GCNNet(num_features, num_classes, hidden_dim, \"cpu\", activation, True).double()\n",
    "optimizer = DPSGD(model.parameters(), noise_scale, gradient_norm_bound, lot_size,\n",
    "                  sample_size, lr=0.01)\n",
    "# Predict\n",
    "optimizer.zero_accum_grad()\n",
    "optimizer.zero_sample_grad()\n",
    "pred = model(data)\n",
    "loss_f = torch.nn.NLLLoss()\n",
    "loss = loss_f(pred, data.y)\n",
    "print(loss)\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "torch.Size([32])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "torch.Size([32, 1433])\n",
      "tensor([ 0.0132,  0.0627, -0.0115, -0.1592, -0.0145,  0.0328,  0.0764],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([7])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "torch.Size([7, 32])\n"
     ]
    }
   ],
   "source": [
    "optimizer.per_sample_step()\n",
    "#optimizer.step(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

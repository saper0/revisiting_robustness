{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from strn_and_rbstness.attacks import Attack, create_attack\n",
    "from strn_and_rbstness.data import GraphDataset, split\n",
    "from strn_and_rbstness.helper.utils import accuracy, count_edges\n",
    "from strn_and_rbstness.models import create_model\n",
    "from strn_and_rbstness.train import _train\n",
    "from common import CSBM\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample CSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Separability:\n",
      "n_corr: 1211\n",
      "n_wrong: 789\n",
      "Structure Separability:\n",
      "n_corr: 1665\n",
      "n_wrong: 335\n",
      "Likelihood Separability:\n",
      "n_corr: 1691\n",
      "n_wrong: 309\n",
      "Dim: 35\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "n = 5000\n",
    "avg_intra_degree = 1.5 * 2 # intra_edges_per_node * 2\n",
    "avg_inter_degree = 0.5 * 2\n",
    "p = avg_intra_degree * 2 / (n - 1)\n",
    "q = avg_inter_degree * 2 / (n - 1)\n",
    "K = 0.5 # Defines distance between means of the gauÃŸians in sigma-units\n",
    "sigma = 0.1\n",
    "d = round(n / math.log(n)**2)\n",
    "mu = np.array([K*sigma / (2 * d**0.5) for i in range(d)], dtype=np.float32)\n",
    "cov = sigma**2 * np.identity(d, dtype=np.float32)\n",
    "\n",
    "# X, A ~ CSBM(n, p, q, mu, cov)\n",
    "csbm = CSBM(p, q, mu, cov)\n",
    "X, A, y = csbm.sample(n, seed=0)\n",
    "#csbm.check_separabilities(X, A, y)\n",
    "print(f\"Dim: {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure GNN & Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Currently on gpu device cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"DenseGCN\",\n",
    "    n_filters=64,\n",
    ")\n",
    "train_params = dict(\n",
    "    loss_type=\"CE\",\n",
    "    lr=1e-2,\n",
    "    weight_decay=1e-3,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    use_selftrain = False, \n",
    "    use_advtrain = False,\n",
    ")\n",
    "attack = \"PGD\"\n",
    "attack_params = dict(\n",
    "    epochs=200,\n",
    "    base_lr=1e-2,\n",
    "    scale_lr_with_n_attacked_edges=True,\n",
    "    loss_type=\"tanhMargin\" # or tanhMargin or CW\n",
    ")\n",
    "epsilon = 0.05\n",
    "\n",
    "# Other\n",
    "split_params = {\n",
    "    \"strategy\": \"normal\", # or \"custom\"\n",
    "    \"p_trn\": 1,\n",
    "    \"p_tst\": 0, # \"normal\" uses 1 - p_trn, only for custom split strategy\n",
    "    \"p_selftrn\": 0 # Refers to unlabeled data, which is not test data, \n",
    "                    # only for custom split strategy\n",
    "}\n",
    "verbosity_params = dict(\n",
    "    display_steps = 100\n",
    ")   \n",
    "# Device\n",
    "device = 0\n",
    "if not torch.cuda.is_available():\n",
    "    device == \"cpu\", \"CUDA is not availble, set device to 'cpu'\"\n",
    "else:\n",
    "    device = torch.device(f\"cuda:{device}\")\n",
    "    logging.info(f\"Currently on gpu device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Epoch    0: loss_train: 0.69319, loss_val: 0.69304, acc_train: 0.51051, acc_val: 0.49251\n",
      "INFO:root:\n",
      "Epoch  100: loss_train: 0.56284, loss_val: 0.61014, acc_train: 0.73073, acc_val: 0.67333\n",
      "INFO:root:\n",
      "Epoch  200: loss_train: 0.52982, loss_val: 0.60279, acc_train: 0.76476, acc_val: 0.68531\n",
      "INFO:root:\n",
      "Epoch  300: loss_train: 0.51179, loss_val: 0.60599, acc_train: 0.78278, acc_val: 0.68432\n",
      "INFO:root:\n",
      "Epoch  400: loss_train: 0.51493, loss_val: 0.60102, acc_train: 0.77277, acc_val: 0.70330\n",
      "INFO:root:\n",
      "Epoch  500: loss_train: 0.51157, loss_val: 0.60137, acc_train: 0.78078, acc_val: 0.70130\n",
      "INFO:root:\n",
      "Epoch  600: loss_train: 0.51748, loss_val: 0.60674, acc_train: 0.77778, acc_val: 0.68831\n",
      "INFO:root:\n",
      "Epoch  700: loss_train: 0.51202, loss_val: 0.59716, acc_train: 0.76877, acc_val: 0.69131\n",
      "INFO:root:\n",
      "Epoch  800: loss_train: 0.51189, loss_val: 0.59494, acc_train: 0.78979, acc_val: 0.69630\n",
      "INFO:root:\n",
      "Epoch  584: loss_train: 0.51144, loss_val: 0.58559, acc_train: 0.78278, acc_val: 0.70829\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "split_ids = split(y, split_params, seed)\n",
    "X_gpu = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "A_gpu = torch.tensor(A, dtype=torch.float32, device=device)\n",
    "y_gpu = torch.tensor(y, device=device)\n",
    "graph = GraphDataset((X_gpu, A_gpu, y_gpu), split_ids)\n",
    "model_params = dict(**model_params, \n",
    "                    n_features=graph.get_n_features(), \n",
    "                    n_classes=graph.get_n_classes())\n",
    "model = create_model(model_params).to(device)\n",
    "statistics = _train(model, graph, train_params, verbosity_params, None)\n",
    "best_epoch = np.argmin(statistics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6973026990890503\n"
     ]
    }
   ],
   "source": [
    "idx_all = np.arange(len(y))\n",
    "model.eval()\n",
    "logits = model(X_gpu, A_gpu)\n",
    "acc_trn = accuracy(logits, y_gpu, split_ids[1])\n",
    "print(acc_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attack GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Edges: 4026 -> budget: 201\n",
      "Accuracy: 0.6485000252723694\n"
     ]
    }
   ],
   "source": [
    "adversary = create_attack(attack, attr=X_gpu, adj=A_gpu, labels=y_gpu, \n",
    "                            model=model, idx_attack=idx_all, device=device, \n",
    "                            binary_attr=False,\n",
    "                            make_undirected=True, \n",
    "                            **attack_params)\n",
    "m  = count_edges(A_gpu, idx_all)\n",
    "n_perturbations = int(round(epsilon * m))\n",
    "print(f\"#Edges: {m} -> budget: {n_perturbations}\")\n",
    "adversary.attack(n_perturbations, _run=None)\n",
    "A_pert, X_pert = adversary.get_pertubations()\n",
    "logits, accuracy = Attack.evaluate_global(model, X_pert, A_pert, y_gpu, idx_all)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(row=tensor([   0,    1,    1,  ..., 1999, 1999, 1999], device='cuda:0'),\n",
       "             col=tensor([1033,  369,  929,  ..., 1334, 1413, 1869], device='cuda:0'),\n",
       "             val=tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'),\n",
       "             size=(2000, 2000), nnz=8444, density=0.21%)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Separability:\n",
      "n_corr: 594\n",
      "n_wrong: 405\n",
      "Structure Separability:\n",
      "n_corr: 725\n",
      "n_wrong: 274\n",
      "Likelihood Separability:\n",
      "n_corr: 754\n",
      "n_wrong: 245\n"
     ]
    }
   ],
   "source": [
    "csbm.check_separabilities(X, A, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2    3    6    7    8   11   13   15   16   18   21   22   23   26\n",
      "   29   30   32   33   34   36   40   41   42   44   45   46   50   51\n",
      "   52   55   56   57   62   66   69   70   72   77   78   79   82   84\n",
      "   85   86   91   92   93   94   97   98  102  103  106  107  108  109\n",
      "  111  112  113  115  116  117  118  120  123  124  127  131  132  134\n",
      "  137  139  141  142  143  144  148  150  153  154  156  157  159  163\n",
      "  164  165  166  167  168  169  171  172  174  175  176  180  181  184\n",
      "  188  190  191  198  200  202  203  204  208  209  210  212  215  216\n",
      "  217  222  229  231  232  234  238  242  243  244  245  246  248  249\n",
      "  250  251  252  254  255  258  265  267  268  269  270  271  272  273\n",
      "  278  284  285  286  287  288  289  291  293  294  295  298  299  300\n",
      "  302  304  305  307  310  314  316  317  319  320  321  322  324  325\n",
      "  326  328  330  331  332  333  335  337  338  339  341  344  345  348\n",
      "  349  353  356  358  359  361  362  363  364  366  368  370  373  381\n",
      "  382  384  385  389  390  392  393  395  397  398  400  403  405  406\n",
      "  408  411  412  414  416  417  418  422  425  427  429  431  433  434\n",
      "  435  436  438  440  443  446  448  449  450  453  455  457  460  462\n",
      "  464  466  467  472  476  477  479  482  483  484  485  487  488  489\n",
      "  490  494  495  497  498  500  502  503  504  505  508  509  511  513\n",
      "  514  516  519  520  521  522  525  526  527  528  531  532  535  537\n",
      "  539  543  545  546  547  549  552  553  555  558  559  563  564  566\n",
      "  568  570  571  572  575  578  581  582  583  586  588  590  591  593\n",
      "  602  607  608  609  612  613  614  618  620  621  622  624  625  627\n",
      "  628  629  630  632  634  637  638  639  641  642  643  644  646  648\n",
      "  649  650  655  656  657  661  662  664  666  667  668  670  671  674\n",
      "  675  676  677  680  685  687  688  690  692  693  694  695  696  701\n",
      "  703  704  705  708  709  718  719  722  723  724  725  726  727  733\n",
      "  735  736  737  738  740  741  743  745  746  747  750  751  753  755\n",
      "  756  757  758  762  764  765  768  773  775  777  778  779  780  783\n",
      "  784  786  787  788  790  792  793  794  795  796  797  801  802  803\n",
      "  804  811  813  815  818  820  821  822  825  827  828  830  831  833\n",
      "  835  838  840  842  843  845  847  850  852  853  854  855  857  859\n",
      "  861  863  864  866  867  868  871  875  876  878  879  880  884  885\n",
      "  887  888  893  894  895  897  898  900  903  904  906  911  912  913\n",
      "  915  922  923  928  930  931  932  933  936  937  938  939  941  944\n",
      "  947  948  949  951  953  954  956  957  958  961  963  966  967  970\n",
      "  972  973  974  975  977  978  979  980  981  984  985  988  989  990\n",
      "  992  994  995  996  997  998  999 1001 1003 1006 1007 1009 1010 1012\n",
      " 1016 1017 1018 1020 1025 1026 1028 1029 1030 1032 1034 1035 1036 1039\n",
      " 1040 1041 1042 1043 1045 1046 1047 1049 1050 1052 1053 1054 1056 1060\n",
      " 1061 1062 1063 1064 1069 1070 1072 1073 1075 1078 1087 1089 1090 1092\n",
      " 1093 1098 1103 1109 1113 1114 1115 1116 1119 1121 1125 1128 1129 1131\n",
      " 1132 1133 1134 1135 1136 1139 1140 1148 1151 1152 1153 1155 1156 1160\n",
      " 1161 1162 1164 1166 1168 1169 1172 1174 1175 1178 1183 1184 1188 1189\n",
      " 1190 1194 1195 1201 1203 1204 1205 1206 1207 1209 1214 1215 1220 1221\n",
      " 1224 1225 1226 1232 1236 1238 1239 1246 1247 1248 1251 1252 1256 1258\n",
      " 1259 1260 1261 1263 1264 1265 1266 1272 1273 1277 1281 1283 1286 1290\n",
      " 1291 1294 1296 1297 1300 1301 1304 1305 1306 1308 1309 1313 1314 1315\n",
      " 1317 1318 1321 1322 1323 1326 1327 1328 1331 1336 1337 1338 1340 1343\n",
      " 1345 1353 1354 1355 1358 1359 1362 1363 1364 1366 1367 1368 1369 1371\n",
      " 1373 1374 1376 1377 1378 1380 1383 1385 1386 1390 1393 1394 1398 1402\n",
      " 1403 1404 1408 1409 1411 1412 1415 1419 1423 1427 1429 1430 1431 1435\n",
      " 1436 1437 1438 1441 1444 1447 1449 1450 1453 1454 1455 1456 1457 1460\n",
      " 1465 1466 1469 1471 1472 1473 1475 1476 1477 1479 1482 1484 1486 1489\n",
      " 1491 1495 1500 1501 1502 1504 1505 1506 1507 1509 1511 1513 1518 1519\n",
      " 1521 1522 1524 1530 1531 1533 1536 1538 1544 1548 1549 1550 1551 1552\n",
      " 1554 1555 1557 1558 1559 1560 1561 1562 1563 1564 1568 1573 1575 1580\n",
      " 1581 1582 1585 1590 1591 1593 1595 1602 1603 1606 1608 1609 1610 1611\n",
      " 1613 1614 1617 1620 1622 1624 1626 1632 1634 1636 1637 1638 1639 1640\n",
      " 1642 1643 1645 1647 1649 1650 1656 1657 1663 1668 1669 1673 1674 1676\n",
      " 1678 1679 1687 1690 1691 1693 1696 1698 1699 1702 1704 1705 1708 1710\n",
      " 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1725 1732 1735\n",
      " 1737 1739 1740 1745 1749 1750 1752 1754 1757 1758 1759 1764 1766 1767\n",
      " 1769 1771 1774 1775 1776 1777 1778 1780 1782 1785 1786 1788 1789 1790\n",
      " 1792 1794 1798 1799 1800 1803 1805 1807 1809 1810 1812 1813 1815 1817\n",
      " 1819 1822 1824 1827 1830 1831 1832 1834 1836 1837 1838 1839 1840 1841\n",
      " 1842 1844 1845 1846 1851 1855 1856 1857 1858 1860 1862 1866 1867 1873\n",
      " 1874 1875 1876 1879 1880 1881 1883 1884 1889 1890 1891 1895 1896 1898\n",
      " 1899 1908 1909 1911 1913 1914 1918 1920 1921 1922 1929 1930 1932 1935\n",
      " 1938 1940 1942 1943 1947 1948 1949 1950 1952 1954 1957 1960 1961 1963\n",
      " 1966 1967 1969 1973 1974 1975 1978 1980 1981 1983 1984 1990 1991 1992\n",
      " 1993 1994 1996 1997 1998]\n",
      "[   0    1    4 ... 1989 1995 1999]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(np.array(split_ids[0])))\n",
    "print(np.sort(np.array(split_ids[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

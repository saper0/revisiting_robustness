{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.graph_models import create_graph_model\n",
    "import numpy as np\n",
    "import torch\n",
    "import exp_eval_robustness\n",
    "import exp_train\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = dict(\n",
    "    graph_model = 'CSBM',\n",
    "    classes = 2,\n",
    "    n = 1000,\n",
    "    n_per_class_trn = 400,\n",
    "    K = 1,\n",
    "    sigma = 1,\n",
    "    avg_within_class_degree = 1.58 * 2,\n",
    "    avg_between_class_degree = 0.37 * 2,\n",
    "    inductive_samples = 100,\n",
    "    m=2,\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GATv2\",\n",
    "    model=\"GATv2\",\n",
    "    #n_filters=64,\n",
    "    dropout=0.,\n",
    "    #GATP\n",
    "    dropout_neighbourhood=0.3,\n",
    "    n_heads=8,\n",
    "    n_features_per_head=8,\n",
    "    #MLP\n",
    "    hidden_channels=256,\n",
    "    #APPNP\n",
    "    #n_hidden=64,\n",
    "    #K=10,\n",
    "    #alpha=0.05,\n",
    "    #LP\n",
    "    use_label_propagation=False,\n",
    "    lp_layers=50,\n",
    "    lp_alpha=0.7,\n",
    "    lp_use_clamping=False,\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-3,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "\n",
    "attack_params = dict(\n",
    "    attack = \"GRBCD\",\n",
    "    max_robustness = 100,\n",
    "    surrogate_model_params = dict(\n",
    "        label=\"LinearGCN\",\n",
    "        model=\"LinearGCN\",\n",
    "        n_filter=64,\n",
    "        dropout=0.5,\n",
    "    ),\n",
    "    surrogate_train_params = dict(\n",
    "        lr=0.1,\n",
    "        weight_decay=1e-4,\n",
    "        patience=300,\n",
    "        max_epochs=3000,\n",
    "    ),\n",
    "    power_law_test=True,\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    display_steps = 100,\n",
    "    debug_lvl = \"info\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"cpu\",\n",
    "    allow_tf32 = False,\n",
    "    sacred_metrics = True\n",
    ")\n",
    "\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:05:39 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-11-11 10:05:39 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 1, 'sigma': 1, 'avg_within_class_degree': 3.16, 'avg_between_class_degree': 0.74, 'inductive_samples': 100, 'm': 2}\n",
      "2022-11-11 10:05:39 (INFO): model_params: {'label': 'GATv2', 'model': 'GATv2', 'dropout': 0.0, 'dropout_neighbourhood': 0.3, 'n_heads': 8, 'n_features_per_head': 8, 'hidden_channels': 256, 'use_label_propagation': False, 'lp_layers': 50, 'lp_alpha': 0.7, 'lp_use_clamping': False}\n",
      "2022-11-11 10:05:39 (INFO): train_params: {'lr': 0.1, 'weight_decay': 0.001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-11-11 10:05:39 (INFO): attack_params: {'attack': 'GRBCD', 'max_robustness': 100, 'surrogate_model_params': {'label': 'LinearGCN', 'model': 'LinearGCN', 'n_filter': 64, 'dropout': 0.5}, 'surrogate_train_params': {'lr': 0.1, 'weight_decay': 0.0001, 'patience': 300, 'max_epochs': 3000}, 'power_law_test': True}\n",
      "2022-11-11 10:05:39 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-11-11 10:05:39 (INFO): other_params: {'device': 'cpu', 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-11-11 10:05:39 (INFO): seed: 8\n",
      "2022-11-11 10:05:39 (INFO): db_collection: None\n",
      "2022-11-11 10:05:39 (INFO): \n",
      "Epoch    0: loss_train: 0.77652, loss_val: 0.67711, acc_train: 0.52625, acc_val: 0.58500\n",
      "2022-11-11 10:05:42 (INFO): \n",
      "Epoch  100: loss_train: 0.41349, loss_val: 0.35173, acc_train: 0.80375, acc_val: 0.87500\n",
      "2022-11-11 10:05:45 (INFO): \n",
      "Epoch  200: loss_train: 0.44974, loss_val: 0.40256, acc_train: 0.78125, acc_val: 0.82000\n",
      "2022-11-11 10:05:47 (INFO): \n",
      "Epoch  300: loss_train: 0.43767, loss_val: 0.41341, acc_train: 0.77750, acc_val: 0.81000\n",
      "2022-11-11 10:05:50 (INFO): \n",
      "Epoch  400: loss_train: 0.42002, loss_val: 0.40472, acc_train: 0.79000, acc_val: 0.82000\n",
      "2022-11-11 10:05:50 (INFO): \n",
      "Epoch  104: loss_train: 0.42532, loss_val: 0.31292, acc_train: 0.79625, acc_val: 0.88500\n",
      "  1%|          | 1/100 [00:29<48:09, 29.19s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3075782/3202882534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#result = exp_train.run(data_params, model_params, train_params, verbosity_params, other_params, seed, None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_eval_robustness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/sacred/config/captured_function.py\u001b[0m in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# =================== run actual function =================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mConfigError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m# =========================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/exp_eval_robustness.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, db_collection, _run)\u001b[0m\n\u001b[1;32m    301\u001b[0m               surrogate_train_params, verbosity_params, _run)\n\u001b[1;32m    302\u001b[0m         \u001b[0msurrogate_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     results_dict = evaluate_robustness(model, \n\u001b[0m\u001b[1;32m    304\u001b[0m                                        \u001b[0mlabel_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                                        \u001b[0mgraph_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/eval.py\u001b[0m in \u001b[0;36mevaluate_robustness\u001b[0;34m(model, label_prop, graph_model, X_np, A_np, y_np, inductive_samples, attack_params, surrogate_model, device)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbayes_separable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgnn_separable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m#print(f\"{c_robustness}: Bayes_sep: {bayes_separable}; GNN_sep: {gnn_separable}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0madv_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_adversarial_pert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mc_robustness\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_robustness\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0madv_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/attacks/rbcd.py\u001b[0m in \u001b[0;36mcreate_adversarial_pert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             self.edge_index, flipped_edges = self.attack(\n\u001b[0m\u001b[1;32m    719\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 idx_attack=self.idx_attack, budget=1)\n",
      "\u001b[0;32m~/src/csbm/src/attacks/rbcd.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/attacks/rbcd.py\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, x, edge_index, labels, budget, idx_attack, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# Loop over the epochs (Algorithm 1, line 5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_sequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             scalars = self.step(step, x, edge_index, labels,\n\u001b[0m\u001b[1;32m    158\u001b[0m                                 budget, idx_attack, **kwargs)\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/attacks/rbcd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, step_size, x, edge_index, labels, budget, idx_attack, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get predictions (Algorithm 2, line 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Calculate loss for attacked nodes (Algorithm 2, line 8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_attack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/attacks/rbcd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         adj = torch_sparse.SparseTensor.from_edge_index(\n\u001b[1;32m    200\u001b[0m             edge_index, edge_weight, (self.n, self.n), is_sorted=True)\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample_random_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/models/gat.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, adj)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/torch_geometric/nn/conv/gatv2_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         out = self.propagate(edge_index, x=(x_l, x_r), edge_attr=edge_attr,\n\u001b[0m\u001b[1;32m    221\u001b[0m                              size=None)\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                         \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/models/gat.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(exp_eval_robustness)\n",
    "importlib.reload(exp_train)\n",
    "#result = exp_train.run(data_params, model_params, train_params, verbosity_params, other_params, seed, None)\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 16:00:42 (INFO): \n",
      "Epoch    0: loss_train: 0.74230, loss_val: 0.74731, acc_train: 0.32375, acc_val: 0.23500\n",
      "2022-11-08 16:00:42 (INFO): \n",
      "Epoch  100: loss_train: 0.21736, loss_val: 0.27384, acc_train: 0.91625, acc_val: 0.89500\n",
      "2022-11-08 16:00:43 (INFO): \n",
      "Epoch  200: loss_train: 0.21414, loss_val: 0.27090, acc_train: 0.92000, acc_val: 0.89500\n",
      "2022-11-08 16:00:43 (INFO): \n",
      "Epoch  300: loss_train: 0.20504, loss_val: 0.27502, acc_train: 0.91625, acc_val: 0.89000\n",
      "2022-11-08 16:00:44 (INFO): \n",
      "Epoch  400: loss_train: 0.21400, loss_val: 0.26903, acc_train: 0.91125, acc_val: 0.90500\n",
      "2022-11-08 16:00:44 (INFO): \n",
      "Epoch  500: loss_train: 0.21238, loss_val: 0.27094, acc_train: 0.91125, acc_val: 0.90000\n",
      "2022-11-08 16:00:44 (INFO): \n",
      "Epoch  600: loss_train: 0.21301, loss_val: 0.26617, acc_train: 0.92375, acc_val: 0.89500\n",
      "2022-11-08 16:00:45 (INFO): \n",
      "Epoch  366: loss_train: 0.22549, loss_val: 0.24665, acc_train: 0.90500, acc_val: 0.90500\n"
     ]
    }
   ],
   "source": [
    "from src.data import split\n",
    "from src.models import create_model\n",
    "from src.train import train_inductive, train_transductive\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"LinearGCN\",\n",
    "    n_filter=64,\n",
    "    dropout=0.5,\n",
    "    use_label_propagation=False,\n",
    ")\n",
    "train_params = dict(\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-3,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "_run = None\n",
    "device = torch.device(f\"cuda:{0}\")\n",
    "\n",
    "# Sample Graph\n",
    "graph_model = create_graph_model(data_params)\n",
    "X_np, A_np, y_np = graph_model.sample(data_params[\"n\"], seed)\n",
    "X = torch.tensor(X_np, dtype=torch.float32, device=device)\n",
    "A = torch.tensor(A_np, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y_np, device=device)\n",
    "split_trn, split_val = split(y_np, data_params)\n",
    "\n",
    "# Create Model\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=X_np.shape[1], \n",
    "                        n_classes=data_params[\"classes\"])\n",
    "model = create_model(model_params_trn).to(device)\n",
    "#logging.info(model)\n",
    "\n",
    "# Train Model\n",
    "if train_params[\"inductive\"]:\n",
    "    train = train_inductive\n",
    "else:\n",
    "    train = train_transductive\n",
    "trn_tracker = train(model, None, X, A, y, split_trn, split_val, train_params,\n",
    "                    verbosity_params, _run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 64])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([21, 2])\n"
     ]
    }
   ],
   "source": [
    "W1 = model.layers[0][0]._linear.weight.T\n",
    "W2 = model.layers[1][0]._linear.weight.T\n",
    "print(W1.shape)\n",
    "print(W2.shape)\n",
    "print(W1.matmul(W2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseGCN(\n",
      "  (activation): Identity()\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (gcn_0): DenseGraphConvolution(\n",
      "        (_linear): Linear(in_features=21, out_features=64, bias=False)\n",
      "      )\n",
      "      (activation_0): Identity()\n",
      "      (dropout_0): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (gcn_1): DenseGraphConvolution(\n",
      "        (_linear): Linear(in_features=64, out_features=2, bias=False)\n",
      "      )\n",
      "      (softmax_1): LogSoftmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.gcn import DenseGCN\n",
    "isinstance(model, DenseGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model.activation, torch.nn.Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2845, -0.1751,  0.0541,  ...,  0.3195,  0.0939,  0.0529],\n",
       "        [-0.0133, -0.1708,  0.0041,  ..., -0.0677, -0.3852, -0.0863],\n",
       "        [ 0.0237, -0.1400,  0.0761,  ..., -0.0926, -0.1117, -0.0352],\n",
       "        ...,\n",
       "        [-0.1547, -0.6180,  0.0105,  ..., -0.4443, -0.1026, -0.1262],\n",
       "        [-0.0155,  0.1586,  0.4082,  ...,  0.2353, -0.1754, -0.0009],\n",
       "        [-0.1066, -0.2037, -0.0348,  ..., -0.1079, -0.1091, -0.2001]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0][0]._linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    label=\"SGC\",\n",
    "    model=\"SGC\",\n",
    "    K=2,\n",
    "    use_label_propagation=False,\n",
    ")\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=X_np.shape[1], \n",
    "                        n_classes=data_params[\"classes\"])\n",
    "sgc = create_model(model_params_trn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseGraphConvolution(\n",
       "  (_linear): Linear(in_features=21, out_features=64, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SGC(\n",
       "  (sgc): SGConv(21, 2, K=2)\n",
       ")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgc.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(10):\n",
    "        yield i\n",
    "    yield None\n",
    "\n",
    "\n",
    "mygen = gen()\n",
    "def call_gen():\n",
    "    return next(mygen)\n",
    "\n",
    "for i in range(11):\n",
    "    print(call_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUBLAS_WORKSPACE_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3778094/1329080253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUBLAS_WORKSPACE_CONFIG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CUBLAS_WORKSPACE_CONFIG'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 14:11:26 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-08-10 14:11:26 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 0.5, 'sigma': 1, 'avg_within_class_degree': 3.0, 'avg_between_class_degree': 1.0, 'inductive_samples': 1000}\n",
      "2022-08-10 14:11:26 (INFO): model_params: {'label': 'GCN', 'model': 'DenseGCN', 'n_filters': 64}\n",
      "2022-08-10 14:11:26 (INFO): train_params: {'lr': 0.01, 'weight_decay': 0.001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-08-10 14:11:26 (INFO): attack_params: {'attack': 'l2'}\n",
      "2022-08-10 14:11:26 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-08-10 14:11:26 (INFO): other_params: {'device': 0, 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-08-10 14:11:26 (INFO): seed: 1\n",
      "2022-08-10 14:11:26 (INFO): db_collection: None\n",
      "2022-08-10 14:11:26 (INFO): Currently on gpu device cuda:0\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch    0: loss_train: 0.70102, loss_val: 0.69805, acc_train: 0.47250, acc_val: 0.49500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  100: loss_train: 0.41914, loss_val: 0.58875, acc_train: 0.80500, acc_val: 0.68500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  200: loss_train: 0.41618, loss_val: 0.60138, acc_train: 0.80000, acc_val: 0.70000\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch  300: loss_train: 0.40287, loss_val: 0.60636, acc_train: 0.81750, acc_val: 0.68500\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch   66: loss_train: 0.47474, loss_val: 0.58023, acc_train: 0.77750, acc_val: 0.68500\n",
      "2022-08-10 14:11:50 (INFO): Prediction Statistics:\n",
      "2022-08-10 14:11:50 (INFO): Count BC: 861.0 GNN: 694.0\n",
      "2022-08-10 14:11:50 (INFO): Count Structure BC: 855.0 Feature BC: 590.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC and GNN: 640.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC not GNN: 221.0 GNN not BC: 54.0\n",
      "2022-08-10 14:11:50 (INFO): Robustness Statistics:\n",
      "2022-08-10 14:11:50 (INFO): BC more robust than GNN: 175.0\n",
      "2022-08-10 14:11:50 (INFO): BC & GNN equal robustness: 101.0\n",
      "2022-08-10 14:11:50 (INFO): BC less robust than GNN: 364.0\n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <BC robust>: 0.12; <GNN robust>: 1.17; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <BC robust>: 0.65; <GNN robust>: 2.40; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <BC robust>: 1.17; <GNN robust>: 3.83; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <BC robust>: 1.54; <GNN robust>: 2.71; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <BC robust>: 2.01; <GNN robust>: 4.02; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <BC robust>: 2.73; <GNN robust>: 5.47; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <BC robust>: 2.79; <GNN robust>: 5.42; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <BC robust>: 3.24; <GNN robust>: 6.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <BC robust>: 3.94; <GNN robust>: 6.43; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <BC robust>: 3.45; <GNN robust>: 3.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <BC robust>: 7.80; <GNN robust>: 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Max(BC robust): 1.00; Max(GNN robust): 6.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Max(BC robust): 2.00; Max(GNN robust): 20.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Max(BC robust): 3.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Max(BC robust): 4.00; Max(GNN robust): 17.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Max(BC robust): 5.00; Max(GNN robust): 16.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Max(BC robust): 6.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Max(BC robust): 6.00; Max(GNN robust): 35.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Max(BC robust): 7.00; Max(GNN robust): 33.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Max(BC robust): 8.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Max(BC robust): 7.00; Max(GNN robust): 8.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Max(BC robust): 10.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Median(BC robust): 0.00; Median(GNN robust): 0.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Median(BC robust): 1.00; Median(GNN robust): 1.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Median(BC robust): 2.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Median(BC robust): 4.00; Median(GNN robust): 5.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Median(BC robust): 3.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Median(BC robust): 8.00; Median(GNN robust): 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <GNN wrt BC robust>: 0.17/0.17. <GNN in wrt BC setting>: 1.17\n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <GNN wrt BC robust>: 0.54/0.74. <GNN in wrt BC setting>: 2.64\n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <GNN wrt BC robust>: 0.99/1.25. <GNN in wrt BC setting>: 4.11\n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <GNN wrt BC robust>: 1.12/1.71. <GNN in wrt BC setting>: 2.81\n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <GNN wrt BC robust>: 1.65/2.08. <GNN in wrt BC setting>: 4.12\n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <GNN wrt BC robust>: 2.28/2.98. <GNN in wrt BC setting>: 5.54\n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <GNN wrt BC robust>: 2.46/2.93. <GNN in wrt BC setting>: 5.66\n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <GNN wrt BC robust>: 2.73/3.70. <GNN in wrt BC setting>: 6.27\n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <GNN wrt BC robust>: 3.41/4.19. <GNN in wrt BC setting>: 6.67\n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <GNN wrt BC robust>: 2.11/3.44. <GNN in wrt BC setting>: 3.22\n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <GNN wrt BC robust>: 6.00/7.80. <GNN in wrt BC setting>: 12.00\n"
     ]
    }
   ],
   "source": [
    "data_params[\"sigma\"] = 1\n",
    "seed = 1\n",
    "\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import calc_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 25 25]\n"
     ]
    }
   ],
   "source": [
    "class_counts = [10, 100, 100]\n",
    "n_samples = 60\n",
    "print(calc_balanced_sample(class_counts, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.Tensor([[0.8, 0.2], [0.1, 0.9]])\n",
    "labels = torch.Tensor([0, 1])\n",
    "logits.argmax(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cuda kernels could not loaded -> no CUDA support!\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.4.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from src.graph_models import create_graph_model\n",
    "import numpy as np\n",
    "import torch\n",
    "import exp_eval_robustness\n",
    "import exp_train\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2])\n",
    "b = 2 * a\n",
    "a[1] = 3\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 11:57:21 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-08-24 11:57:21 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 0.1, 'sigma': 1, 'avg_within_class_degree': 3.16, 'avg_between_class_degree': 0.74, 'inductive_samples': 100}\n",
      "2022-08-24 11:57:21 (INFO): model_params: {'label': 'GCN', 'model': 'GAT', 'n_filter': 64, 'n_heads': 8, 'n_features_per_head': 8, 'droput': 0.0, 'droput_neighbourhood': 0.0, 'use_label_propagation': True, 'lp_layers': 50, 'lp_alpha': 0.8, 'lp_use_clamping': True}\n",
      "2022-08-24 11:57:21 (INFO): train_params: {'lr': 0.1, 'weight_decay': 0.0001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-08-24 11:57:21 (INFO): attack_params: {'attack': 'random'}\n",
      "2022-08-24 11:57:21 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-08-24 11:57:21 (INFO): other_params: {'device': 0, 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-08-24 11:57:21 (INFO): seed: 0\n",
      "2022-08-24 11:57:21 (INFO): db_collection: None\n",
      "2022-08-24 11:57:21 (INFO): Currently on gpu device cuda:0\n",
      "2022-08-24 11:57:21 (INFO): \n",
      "Epoch    0: loss_train: 1.36086, loss_val: 0.72958, acc_train: 0.49875, acc_val: 0.48000\n",
      "2022-08-24 11:57:22 (INFO): \n",
      "Epoch  100: loss_train: 0.78903, loss_val: 0.71384, acc_train: 0.51875, acc_val: 0.49500\n",
      "2022-08-24 11:57:23 (INFO): \n",
      "Epoch  200: loss_train: 0.78954, loss_val: 0.73268, acc_train: 0.49125, acc_val: 0.52000\n",
      "2022-08-24 11:57:24 (INFO): \n",
      "Epoch  300: loss_train: 0.73690, loss_val: 0.69207, acc_train: 0.50375, acc_val: 0.57500\n",
      "2022-08-24 11:57:24 (INFO): \n",
      "Epoch   20: loss_train: 1.01408, loss_val: 0.67464, acc_train: 0.51000, acc_val: 0.60000\n",
      "2022-08-24 11:57:24 (INFO): Testing Trained Model + Label Propagation if specified:\n",
      "2022-08-24 11:57:24 (INFO): \n",
      "Epoch    0: loss_train: 0.51026, loss_val: 0.60603, acc_train: 0.99625, acc_val: 0.82000\n",
      "2022-08-24 11:57:35 (INFO): Prediction Statistics:\n",
      "2022-08-24 11:57:35 (INFO): Count BC: 89.0 GNN: 90.0\n",
      "2022-08-24 11:57:35 (INFO): Count Structure BC: 88.0 Feature BC: 57.0\n",
      "2022-08-24 11:57:35 (INFO): Count BC and GNN: 84.0\n",
      "2022-08-24 11:57:35 (INFO): Count BC not GNN: 5.0 GNN not BC: 6.0\n",
      "2022-08-24 11:57:35 (INFO): Robustness Statistics:\n",
      "2022-08-24 11:57:35 (INFO): BC more robust than GNN: 33.0\n",
      "2022-08-24 11:57:35 (INFO): BC & GNN equal robustness: 22.0\n",
      "2022-08-24 11:57:35 (INFO): BC less robust than GNN: 29.0\n",
      "2022-08-24 11:57:35 (INFO): Degree 0: <BC robust>: 0.00; <GNN robust>: 0.50; \n",
      "2022-08-24 11:57:35 (INFO): Degree 1: <BC robust>: 0.86; <GNN robust>: 0.57; \n",
      "2022-08-24 11:57:35 (INFO): Degree 2: <BC robust>: 1.31; <GNN robust>: 1.40; \n",
      "2022-08-24 11:57:35 (INFO): Degree 3: <BC robust>: 1.85; <GNN robust>: 2.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 4: <BC robust>: 1.89; <GNN robust>: 1.59; \n",
      "2022-08-24 11:57:35 (INFO): Degree 5: <BC robust>: 2.73; <GNN robust>: 2.36; \n",
      "2022-08-24 11:57:35 (INFO): Degree 6: <BC robust>: 3.67; <GNN robust>: 4.50; \n",
      "2022-08-24 11:57:35 (INFO): Degree 7: <BC robust>: -1.00; <GNN robust>: -1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 8: <BC robust>: 5.50; <GNN robust>: 7.50; \n",
      "2022-08-24 11:57:35 (INFO): Degree 9: <BC robust>: -1.00; <GNN robust>: -1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 10: <BC robust>: 4.00; <GNN robust>: 2.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 0: Max(BC robust): 0.00; Max(GNN robust): 1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 1: Max(BC robust): 1.00; Max(GNN robust): 1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 2: Max(BC robust): 2.00; Max(GNN robust): 4.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 3: Max(BC robust): 3.00; Max(GNN robust): 5.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 4: Max(BC robust): 4.00; Max(GNN robust): 6.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 5: Max(BC robust): 5.00; Max(GNN robust): 5.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 6: Max(BC robust): 6.00; Max(GNN robust): 9.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 7: Max(BC robust): -1.00; Max(GNN robust): -1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 8: Max(BC robust): 6.00; Max(GNN robust): 9.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 9: Max(BC robust): -1.00; Max(GNN robust): -1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 10: Max(BC robust): 4.00; Max(GNN robust): 2.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 0: Median(BC robust): 0.00; Median(GNN robust): 0.50; \n",
      "2022-08-24 11:57:35 (INFO): Degree 1: Median(BC robust): 1.00; Median(GNN robust): 1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 2: Median(BC robust): 1.00; Median(GNN robust): 1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 3: Median(BC robust): 2.00; Median(GNN robust): 2.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 4: Median(BC robust): 2.00; Median(GNN robust): 1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 5: Median(BC robust): 3.00; Median(GNN robust): 2.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 6: Median(BC robust): 3.50; Median(GNN robust): 4.50; \n",
      "2022-08-24 11:57:35 (INFO): Degree 7: Median(BC robust): -1.00; Median(GNN robust): -1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 8: Median(BC robust): 5.50; Median(GNN robust): 7.50; \n",
      "2022-08-24 11:57:35 (INFO): Degree 9: Median(BC robust): -1.00; Median(GNN robust): -1.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 10: Median(BC robust): 4.00; Median(GNN robust): 2.00; \n",
      "2022-08-24 11:57:35 (INFO): Degree 0: <GNN wrt BC robust>: 0.00/0.00. <GNN in wrt BC setting>: 0.00\n",
      "2022-08-24 11:57:35 (INFO): Degree 1: <GNN wrt BC robust>: 0.43/0.86. <GNN in wrt BC setting>: 0.57\n",
      "2022-08-24 11:57:35 (INFO): Degree 2: <GNN wrt BC robust>: 1.08/1.42. <GNN in wrt BC setting>: 1.75\n",
      "2022-08-24 11:57:35 (INFO): Degree 3: <GNN wrt BC robust>: 1.35/1.85. <GNN in wrt BC setting>: 2.00\n",
      "2022-08-24 11:57:35 (INFO): Degree 4: <GNN wrt BC robust>: 1.19/2.06. <GNN in wrt BC setting>: 1.69\n",
      "2022-08-24 11:57:35 (INFO): Degree 5: <GNN wrt BC robust>: 2.31/3.00. <GNN in wrt BC setting>: 2.38\n",
      "2022-08-24 11:57:35 (INFO): Degree 6: <GNN wrt BC robust>: 2.67/3.67. <GNN in wrt BC setting>: 4.50\n",
      "2022-08-24 11:57:35 (INFO): Degree 7: <GNN wrt BC robust>: -1.00/-1.00. <GNN in wrt BC setting>: -1.00\n",
      "2022-08-24 11:57:35 (INFO): Degree 8: <GNN wrt BC robust>: 5.50/5.50. <GNN in wrt BC setting>: 7.50\n",
      "2022-08-24 11:57:35 (INFO): Degree 9: <GNN wrt BC robust>: -1.00/-1.00. <GNN in wrt BC setting>: -1.00\n",
      "2022-08-24 11:57:35 (INFO): Degree 10: <GNN wrt BC robust>: 2.00/4.00. <GNN in wrt BC setting>: 2.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction_statistics': {'c_acc_bayes': 89, 'c_acc_gnn': 90, 'c_acc_bayes_structure': 88, 'c_acc_bayes_feature': 57, 'c_acc_bayes_gnn': 84, 'c_acc_bayes_not_gnn': 5, 'c_acc_gnn_not_bayes': 6}, 'robustness_statistics': {'c_bayes_higher_robust': 33, 'c_bayes_gnn_equal_robust': 22, 'c_gnn_higher_robust': 29, 'avg_bayes_robust': {'4': 1.8888888888888888, '1': 0.8571428571428571, '2': 1.3076923076923077, '8': 5.5, '5': 2.7333333333333334, '6': 3.6666666666666665, '3': 1.85, '0': 0.0, '10': 4.0}, 'med_bayes_robust': {'4': 2.0, '1': 1.0, '2': 1.0, '8': 5.5, '5': 3.0, '6': 3.5, '3': 2.0, '0': 0.0, '10': 4.0}, 'std_bayes_robust': {'4': 1.1967032904743342, '1': 0.3499271061118826, '2': 0.6056929133855239, '8': 0.5, '5': 1.730767331432956, '6': 1.3123346456686351, '3': 1.1947803145348521, '0': 0.0, '10': 0.0}, 'max_bayes_robust': {'4': 4.0, '1': 1.0, '2': 2.0, '8': 6.0, '5': 5.0, '6': 6.0, '3': 3.0, '0': 0.0, '10': 4.0}, 'avg_gnn_robust': {'4': 1.588235294117647, '1': 0.5714285714285714, '2': 1.4, '8': 7.5, '5': 2.357142857142857, '6': 4.5, '3': 2.0, '0': 0.5, '10': 2.0}, 'med_gnn_robust': {'4': 1.0, '1': 1.0, '2': 1.0, '8': 7.5, '5': 2.0, '6': 4.5, '3': 2.0, '0': 0.5, '10': 2.0}, 'std_gnn_robust': {'4': 1.6823940760088345, '1': 0.4948716593053935, '2': 1.254325848148452, '8': 1.5, '5': 1.630387458644761, '6': 2.8722813232690143, '3': 1.3416407864998738, '0': 0.5, '10': 0.0}, 'max_gnn_robust': {'4': 6.0, '1': 1.0, '2': 4.0, '8': 9.0, '5': 5.0, '6': 9.0, '3': 5.0, '0': 1.0, '10': 2.0}, 'avg_gnn_wrt_bayes_robust': {'4': 1.1875, '1': 0.42857142857142855, '2': 1.0833333333333333, '8': 5.5, '5': 2.3076923076923075, '6': 2.6666666666666665, '3': 1.35, '0': 0.0, '10': 2.0}, 'med_gnn_wrt_bayes_robust': {'4': 1.0, '1': 0.0, '2': 1.0, '8': 5.5, '5': 2.0, '6': 2.0, '3': 1.5, '0': 0.0, '10': 2.0}, 'std_gnn_wrt_bayes_robust': {'4': 1.2358574958303243, '1': 0.49487165930539345, '2': 0.6400954789890506, '8': 0.5, '5': 1.7269187938956652, '6': 1.5456030825826172, '3': 1.061838029079765, '0': 0.0, '10': 0.0}, 'max_gnn_wrt_bayes_robust': {'4': 4.0, '1': 1.0, '2': 2.0, '8': 6.0, '5': 5.0, '6': 5.0, '3': 3.0, '0': 0.0, '10': 2.0}, 'avg_bayes_robust_when_both': {'4': 2.0625, '1': 0.8571428571428571, '2': 1.4166666666666667, '8': 5.5, '5': 3.0, '6': 3.6666666666666665, '3': 1.85, '0': 0.0, '10': 4.0}, 'med_bayes_robust_when_both': {'4': 2.0, '1': 1.0, '2': 1.0, '8': 5.5, '5': 3.0, '6': 3.5, '3': 2.0, '0': 0.0, '10': 4.0}, 'std_bayes_robust_when_both': {'4': 1.1439378261076953, '1': 0.3499271061118826, '2': 0.4930066485916347, '8': 0.5, '5': 1.6641005886756874, '6': 1.3123346456686351, '3': 1.1947803145348521, '0': 0.0, '10': 0.0}, 'max_bayes_robust_when_both': {'4': 4.0, '1': 1.0, '2': 2.0, '8': 6.0, '5': 5.0, '6': 6.0, '3': 3.0, '0': 0.0, '10': 4.0}, 'avg_gnn_robust_when_both': {'4': 1.6875, '1': 0.5714285714285714, '2': 1.75, '8': 7.5, '5': 2.3846153846153846, '6': 4.5, '3': 2.0, '0': 0.0, '10': 2.0}, 'med_gnn_robust_when_both': {'4': 1.0, '1': 1.0, '2': 2.0, '8': 7.5, '5': 2.0, '6': 4.5, '3': 2.0, '0': 0.0, '10': 2.0}, 'std_gnn_robust_when_both': {'4': 1.6851835953390955, '1': 0.4948716593053935, '2': 1.1636866703140785, '8': 1.5, '5': 1.6888075692384732, '6': 2.8722813232690143, '3': 1.3416407864998738, '0': 0.0, '10': 0.0}, 'max_gnn_robust_when_both': {'4': 6.0, '1': 1.0, '2': 4.0, '8': 9.0, '5': 5.0, '6': 9.0, '3': 5.0, '0': 0.0, '10': 2.0}, 'c_bayes_robust': {4: [3, 0, 2, 2, 3, 4, 2, 3, 1, 2, 1, 2, 0, 2, 4, 2, 1, 0], 1: [0, 1, 1, 1, 1, 1, 1], 2: [1, 1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 2, 2], 8: [5, 6], 5: [5, 0, 4, 2, 1, 2, 3, 5, 3, 3, 0, 5, 2, 1, 5], 6: [2, 3, 5, 3, 2, 4, 4, 2, 5, 5, 6, 3], 3: [0, 0, 1, 1, 3, 2, 3, 0, 1, 3, 3, 3, 3, 3, 3, 2, 0, 3, 2, 1], 0: [0], 10: [4]}, 'c_gnn_robust': {4: [1, 3, 0, 4, 3, 1, 0, 0, 0, 1, 1, 0, 3, 6, 0, 2, 2], 1: [1, 0, 0, 1, 1, 1, 0], 2: [4, 1, 2, 2, 3, 0, 0, 1, 0, 1, 0, 3, 2, 0, 2], 8: [9, 6], 5: [4, 0, 4, 1, 2, 0, 3, 2, 2, 1, 3, 5, 1, 5], 6: [6, 6, 9, 2, 3, 0, 1, 5, 9, 7, 2, 4], 3: [1, 1, 4, 1, 2, 2, 5, 1, 0, 1, 2, 2, 3, 4, 2, 2, 4, 2, 1, 0], 0: [1, 0], 10: [2]}, 'c_gnn_wrt_bayes_robust': {4: [1, 2, 0, 3, 3, 1, 0, 0, 1, 1, 0, 2, 4, 0, 1, 0], 1: [0, 0, 0, 1, 1, 1, 0], 2: [1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 0, 2], 8: [5, 6], 5: [4, 0, 4, 1, 1, 0, 3, 2, 1, 3, 5, 1, 5], 6: [2, 3, 5, 2, 2, 0, 1, 2, 5, 5, 2, 3], 3: [0, 0, 1, 1, 2, 2, 3, 0, 0, 1, 2, 2, 3, 3, 2, 2, 0, 2, 1, 0], 0: [0], 10: [2]}, 'c_bayes_robust_when_both': {4: [3, 2, 2, 3, 4, 2, 3, 1, 2, 2, 0, 2, 4, 2, 1, 0], 1: [0, 1, 1, 1, 1, 1, 1], 2: [1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2], 8: [5, 6], 5: [5, 0, 4, 2, 1, 2, 3, 5, 3, 3, 5, 1, 5], 6: [2, 3, 5, 3, 2, 4, 4, 2, 5, 5, 6, 3], 3: [0, 0, 1, 1, 3, 2, 3, 0, 1, 3, 3, 3, 3, 3, 3, 2, 0, 3, 2, 1], 0: [0], 10: [4]}, 'c_gnn_robust_when_both': {4: [1, 3, 0, 4, 3, 1, 0, 0, 1, 1, 0, 3, 6, 0, 2, 2], 1: [1, 0, 0, 1, 1, 1, 0], 2: [4, 1, 2, 2, 3, 1, 1, 0, 3, 2, 0, 2], 8: [9, 6], 5: [4, 0, 4, 1, 2, 0, 3, 2, 1, 3, 5, 1, 5], 6: [6, 6, 9, 2, 3, 0, 1, 5, 9, 7, 2, 4], 3: [1, 1, 4, 1, 2, 2, 5, 1, 0, 1, 2, 2, 3, 4, 2, 2, 4, 2, 1, 0], 0: [0], 10: [2]}}, 'training_loss': [1.3608568906784058, 1.6480576992034912, 1.8135441541671753, 1.4819728136062622, 1.3198580741882324, 1.0511645078659058, 1.0971531867980957, 1.3788303136825562, 1.2285962104797363, 0.997732400894165, 1.111457109451294, 1.0960640907287598, 1.1196502447128296, 1.327142596244812, 1.3059958219528198, 1.1777141094207764, 1.191856026649475, 1.2918750047683716, 1.0607424974441528, 1.1329569816589355, 1.0140751600265503, 1.1114168167114258, 1.094253659248352, 0.9543939232826233, 0.9845191240310669, 1.0030182600021362, 1.1147854328155518, 0.9506936073303223, 0.986705482006073, 1.0459438562393188, 0.7912876009941101, 0.9647549986839294, 0.8432936072349548, 0.9111549258232117, 0.8934663534164429, 0.8987217545509338, 0.9481701850891113, 0.8646515011787415, 0.9342559576034546, 0.8420329093933105, 0.8435516953468323, 0.8165076375007629, 0.8239116072654724, 0.9081699252128601, 0.8487330079078674, 0.8284931182861328, 0.8631306290626526, 0.795348048210144, 0.8144266605377197, 0.836652398109436, 0.7768115401268005, 0.8064932823181152, 0.7956444621086121, 0.830447256565094, 0.7888851761817932, 0.764885425567627, 0.7663937211036682, 0.8137481808662415, 0.8247042894363403, 0.7945504188537598, 0.8802871704101562, 0.8502864241600037, 0.8057047128677368, 0.9008337259292603, 0.7905930280685425, 0.8055436611175537, 0.7627265453338623, 0.8125106692314148, 0.8010095953941345, 0.8292936086654663, 0.8440927863121033, 0.7719014883041382, 0.7841341495513916, 0.7863793969154358, 0.8149356842041016, 0.828005313873291, 0.8205159902572632, 0.7966553568840027, 0.8315958976745605, 0.8195564150810242, 0.7471005320549011, 0.8687953352928162, 0.8274421095848083, 0.8260844349861145, 0.8539572954177856, 0.828849196434021, 0.8191421627998352, 0.816385805606842, 0.8074793815612793, 0.7862123250961304, 0.7276783585548401, 0.9011965394020081, 0.8136122822761536, 0.8304298520088196, 0.8000180721282959, 0.8118829131126404, 0.8385620713233948, 0.8545641899108887, 0.7719952464103699, 0.771353542804718, 0.789027988910675, 0.798969030380249, 0.9244015216827393, 0.818879246711731, 0.7831497192382812, 0.773933470249176, 0.9370551109313965, 0.8330039978027344, 0.8764515519142151, 0.7597000598907471, 0.8789629340171814, 0.7509558200836182, 0.8445162773132324, 0.7934204339981079, 0.8293579816818237, 0.744587242603302, 0.797607958316803, 0.7738988995552063, 0.7953055500984192, 0.7709508538246155, 0.7499896287918091, 0.828839123249054, 0.7763490080833435, 0.8083338141441345, 0.8240939378738403, 0.7820924520492554, 0.7928957343101501, 0.7851380705833435, 0.8234890699386597, 0.7758452892303467, 0.7934086322784424, 0.8604019284248352, 0.7875109314918518, 0.7538918852806091, 0.7234464883804321, 0.7901034355163574, 0.7804297804832458, 0.8379678130149841, 0.8433554172515869, 0.8296375870704651, 0.7967232465744019, 0.7757192850112915, 0.7701149582862854, 0.7874033451080322, 0.7613323926925659, 0.7917821407318115, 0.7635036706924438, 0.8583893775939941, 0.7558076977729797, 0.7771033644676208, 0.7776329517364502, 0.8843228220939636, 0.855315625667572, 0.7995638847351074, 0.8286136388778687, 0.7638123035430908, 0.7598353028297424, 0.8308634757995605, 0.8071451783180237, 0.7954413890838623, 0.8381589651107788, 0.7852859497070312, 0.719451904296875, 0.8376402854919434, 0.8293905854225159, 0.8311786651611328, 0.743838906288147, 0.7878170609474182, 0.7969979643821716, 0.8237650990486145, 0.8244193196296692, 0.8393121957778931, 0.7849075198173523, 0.7823361754417419, 0.8258249163627625, 0.817776620388031, 0.8066731095314026, 0.756440281867981, 0.8458284735679626, 0.8196331262588501, 0.7720709443092346, 0.7873959541320801, 0.756573498249054, 0.7576220631599426, 0.7731108069419861, 0.76133131980896, 0.751207709312439, 0.7913485169410706, 0.7728394865989685, 0.8070286512374878, 0.7763726115226746, 0.7569764852523804, 0.787803590297699, 0.7612809538841248, 0.8146594762802124, 0.8006367683410645, 0.7306772470474243, 0.7623533606529236, 0.7999837398529053, 0.7818419933319092, 0.7895448207855225, 0.8155027627944946, 0.8277040123939514, 0.7862146496772766, 0.8166744709014893, 0.8173477649688721, 0.7939029932022095, 0.7660031914710999, 0.7887704968452454, 0.8228249549865723, 0.7714751362800598, 0.7691717743873596, 0.7896616458892822, 0.7851848602294922, 0.7584215402603149, 0.8117517232894897, 0.8073694705963135, 0.8155011534690857, 0.8409743309020996, 0.7778862118721008, 0.775651752948761, 0.8342302441596985, 0.7971431612968445, 0.7602490186691284, 0.7941004037857056, 0.7431116700172424, 0.7856743335723877, 0.7886033654212952, 0.799822211265564, 0.7631325721740723, 0.7457460165023804, 0.7919272780418396, 0.7561596632003784, 0.7682656645774841, 0.8208669424057007, 0.759748637676239, 0.8046770691871643, 0.7745219469070435, 0.8439845442771912, 0.8040461540222168, 0.7579248547554016, 0.7984284162521362, 0.8348321318626404, 0.8882961273193359, 0.8105122447013855, 0.7864178419113159, 0.81505286693573, 0.8003606200218201, 0.7764668464660645, 0.7766631841659546, 0.816253662109375, 0.7934783101081848, 0.8543843030929565, 0.7545478940010071, 0.7848361134529114, 0.854790449142456, 0.8161940574645996, 0.8164495229721069, 0.8075264692306519, 0.8006134629249573, 0.7611730694770813, 0.8292855024337769, 0.8353673815727234, 0.8255310654640198, 0.8379088640213013, 0.7656116485595703, 0.7673038244247437, 0.745391309261322, 0.7431274652481079, 0.769580602645874, 0.8433623313903809, 0.7938079237937927, 0.7885060906410217, 0.7886993885040283, 0.817057192325592, 0.7528974413871765, 0.8357886672019958, 0.8110315203666687, 0.7751427292823792, 0.7595958113670349, 0.7999724745750427, 0.8119680285453796, 0.7939741015434265, 0.791796863079071, 0.7612789869308472, 0.7593015432357788, 0.7845860123634338, 0.7914823293685913, 0.7918956279754639, 0.8338081240653992, 0.7728023529052734, 0.8236123919487, 0.7375872731208801, 0.7811663150787354, 0.8135108351707458, 0.8222106695175171, 0.8082904815673828, 0.7847983837127686, 0.7984687685966492, 0.7781291007995605, 0.7368954420089722, 0.717075526714325, 0.769100546836853, 0.7795962691307068, 0.7662118673324585, 0.7466427683830261, 0.8061501383781433, 0.7641649842262268, 0.7851412892341614, 0.7575914859771729, 0.7459128499031067, 0.8430197238922119, 0.8084545135498047, 0.781368613243103, 0.8245278000831604, 0.7813519835472107, 0.8076472282409668, 0.7842895984649658, 0.7967354655265808, 0.7777460217475891, 0.8209195137023926], 'validation_loss': [0.7295780777931213, 1.3368966579437256, 0.7630969882011414, 0.7661547064781189, 0.8575586676597595, 0.7414228916168213, 0.7740965485572815, 0.7702164649963379, 0.758622407913208, 0.7683670520782471, 0.8175309896469116, 0.8359881043434143, 0.802936315536499, 0.7599896788597107, 0.7479063272476196, 0.7219107151031494, 0.6968333721160889, 0.6860479712486267, 0.6841931343078613, 0.681271493434906, 0.6746357083320618, 0.7148756384849548, 0.771334171295166, 0.778479814529419, 0.752116322517395, 0.7387330532073975, 0.7416800856590271, 0.7440292835235596, 0.74656081199646, 0.7422725558280945, 0.7315123677253723, 0.7292109131813049, 0.7363174557685852, 0.7265133857727051, 0.7065145373344421, 0.705837070941925, 0.7136808037757874, 0.7233865261077881, 0.7263858914375305, 0.7173655033111572, 0.7087511420249939, 0.7089555263519287, 0.7144641876220703, 0.7009961009025574, 0.6957414746284485, 0.7099197506904602, 0.7127935290336609, 0.7051500082015991, 0.6946139335632324, 0.6981382966041565, 0.704494297504425, 0.7072241902351379, 0.7085471153259277, 0.7072010636329651, 0.7044481039047241, 0.7021641731262207, 0.7020049095153809, 0.6991231441497803, 0.6961598992347717, 0.6923895478248596, 0.6991849541664124, 0.7090958952903748, 0.7091169953346252, 0.7052335143089294, 0.7050614953041077, 0.7031175494194031, 0.7014890313148499, 0.7062936425209045, 0.7118557095527649, 0.7158028483390808, 0.7068652510643005, 0.6979620456695557, 0.697395384311676, 0.7052781581878662, 0.7053490281105042, 0.7054111361503601, 0.7177450060844421, 0.7304052114486694, 0.7213892340660095, 0.718018114566803, 0.7079704999923706, 0.7069088816642761, 0.7079949975013733, 0.7166441082954407, 0.7122099995613098, 0.7050426602363586, 0.703460156917572, 0.7015359997749329, 0.7021343111991882, 0.7031316161155701, 0.7013669013977051, 0.6980692148208618, 0.693543553352356, 0.6904094815254211, 0.6853129863739014, 0.6888211965560913, 0.6954680681228638, 0.7015888690948486, 0.7091140747070312, 0.7145686149597168, 0.7138393521308899, 0.7112978100776672, 0.7115350961685181, 0.7033497095108032, 0.7081388235092163, 0.7358108758926392, 0.7293978333473206, 0.7087332010269165, 0.7264965772628784, 0.7085171341896057, 0.7539271712303162, 0.7343510389328003, 0.7157949805259705, 0.7224140167236328, 0.7102572917938232, 0.713726818561554, 0.7057873010635376, 0.6899794936180115, 0.6918045282363892, 0.6824467182159424, 0.6869089007377625, 0.6998854279518127, 0.6888981461524963, 0.7030758857727051, 0.7066177129745483, 0.7519577145576477, 0.7323480248451233, 0.7363371849060059, 0.7245720624923706, 0.7253655791282654, 0.7376883029937744, 0.7053253650665283, 0.7033134698867798, 0.6949370503425598, 0.7040854692459106, 0.7247951030731201, 0.6920343041419983, 0.7274294495582581, 0.7443162798881531, 0.7012734413146973, 0.7196271419525146, 0.7148920297622681, 0.6982104778289795, 0.7185974717140198, 0.7027045488357544, 0.6992405652999878, 0.7152306437492371, 0.7010219097137451, 0.7044901847839355, 0.6992475390434265, 0.6965416669845581, 0.7196040153503418, 0.7166796326637268, 0.6934280395507812, 0.6987345814704895, 0.6960861682891846, 0.6949608325958252, 0.6989629864692688, 0.6986247897148132, 0.7085878252983093, 0.7014666199684143, 0.7137739062309265, 0.7012922763824463, 0.7073558568954468, 0.7068192958831787, 0.6992878913879395, 0.7002948522567749, 0.701541006565094, 0.6967648267745972, 0.7026946544647217, 0.6932352185249329, 0.6977620124816895, 0.7138625383377075, 0.705359697341919, 0.7127664089202881, 0.7106080055236816, 0.7055565118789673, 0.6961792707443237, 0.6945327520370483, 0.7075901627540588, 0.7015160322189331, 0.7063300609588623, 0.6989194750785828, 0.6999351382255554, 0.6996653079986572, 0.7003021240234375, 0.7008163332939148, 0.7032424807548523, 0.6984508037567139, 0.6958835124969482, 0.6951080560684204, 0.6909128427505493, 0.6871378421783447, 0.6854796409606934, 0.6862196922302246, 0.6924026608467102, 0.7010087370872498, 0.6919789910316467, 0.6970797181129456, 0.7068867683410645, 0.7326756119728088, 0.7055432200431824, 0.7132797837257385, 0.7111151814460754, 0.7100698947906494, 0.7124991416931152, 0.710246741771698, 0.720835268497467, 0.7321274280548096, 0.690073549747467, 0.7115851640701294, 0.6894720196723938, 0.7023704051971436, 0.709505021572113, 0.6981655955314636, 0.7736247181892395, 0.7071674466133118, 0.7268422842025757, 0.7155216336250305, 0.7268087267875671, 0.7189511060714722, 0.6946512460708618, 0.7095391154289246, 0.685536801815033, 0.6865177750587463, 0.6848080158233643, 0.6795237064361572, 0.6876543164253235, 0.6889901757240295, 0.700675368309021, 0.7066759467124939, 0.7045827507972717, 0.7054226398468018, 0.7043803334236145, 0.7048656344413757, 0.6977245807647705, 0.6964635252952576, 0.6978926062583923, 0.6941834092140198, 0.6991970539093018, 0.6983380913734436, 0.6984286308288574, 0.6997617483139038, 0.7014124393463135, 0.7141385674476624, 0.7020544409751892, 0.7089405655860901, 0.7117717862129211, 0.7011951208114624, 0.696298360824585, 0.7300884127616882, 0.700432300567627, 0.6945544481277466, 0.6881508827209473, 0.7054927945137024, 0.7251215577125549, 0.7009246945381165, 0.7469969391822815, 0.707420825958252, 0.7369771003723145, 0.7170909643173218, 0.723938524723053, 0.7416350841522217, 0.6986510753631592, 0.7117249965667725, 0.7013288736343384, 0.6998332738876343, 0.6928113698959351, 0.6936067342758179, 0.6946442127227783, 0.7162590026855469, 0.7174203395843506, 0.7383860945701599, 0.7042993307113647, 0.7600876092910767, 0.6938621401786804, 0.7320144176483154, 0.7641716599464417, 0.6980674266815186, 0.7082798480987549, 0.7026079297065735, 0.7338306307792664, 0.702200174331665, 0.7214898467063904, 0.6961361765861511, 0.7154893279075623, 0.6878736019134521, 0.7029607892036438, 0.6923032402992249, 0.7310750484466553, 0.6875199675559998, 0.7439540028572083, 0.7103261351585388, 0.7194561958312988, 0.707268476486206, 0.7261226177215576, 0.7087806463241577, 0.7042949795722961, 0.7147178649902344, 0.6914882659912109, 0.6920650005340576, 0.6941274404525757, 0.7060289978981018, 0.7061465978622437, 0.6989775896072388, 0.7028026580810547, 0.7107300758361816, 0.7314769625663757, 0.7056299448013306, 0.7060928344726562, 0.7061952948570251, 0.7191168069839478, 0.6967934966087341, 0.742750883102417, 0.6958625316619873, 0.7336689829826355, 0.6972324848175049, 0.763404130935669, 0.7088743448257446, 0.7017748355865479, 0.709826648235321], 'training_accuracy': [0.4987500011920929, 0.5099999904632568, 0.5237500071525574, 0.518750011920929, 0.48374998569488525, 0.5062499642372131, 0.5074999928474426, 0.4387499988079071, 0.4737499952316284, 0.5199999809265137, 0.5, 0.5224999785423279, 0.5262500047683716, 0.4675000011920929, 0.4962500035762787, 0.4962500035762787, 0.5174999833106995, 0.5262500047683716, 0.5049999952316284, 0.4912499785423279, 0.5099999904632568, 0.4412499964237213, 0.47999998927116394, 0.5424999594688416, 0.5099999904632568, 0.4712499976158142, 0.48624998331069946, 0.4762499928474426, 0.47999998927116394, 0.4624999761581421, 0.5324999690055847, 0.4975000023841858, 0.5362499952316284, 0.48624998331069946, 0.5249999761581421, 0.5475000143051147, 0.5137500166893005, 0.5137500166893005, 0.4737499952316284, 0.5412499904632568, 0.512499988079071, 0.512499988079071, 0.5149999856948853, 0.4899999797344208, 0.48624998331069946, 0.5224999785423279, 0.5262500047683716, 0.5462499856948853, 0.5112499594688416, 0.4762499928474426, 0.5137500166893005, 0.5099999904632568, 0.5399999618530273, 0.4975000023841858, 0.5162500143051147, 0.5362499952316284, 0.5625, 0.5299999713897705, 0.492499977350235, 0.4987500011920929, 0.4937499761581421, 0.48249998688697815, 0.5287500023841858, 0.4962500035762787, 0.5087499618530273, 0.5012499690055847, 0.53125, 0.5137500166893005, 0.5424999594688416, 0.5249999761581421, 0.5362499952316284, 0.5262500047683716, 0.5262500047683716, 0.48749998211860657, 0.5349999666213989, 0.5262500047683716, 0.5049999952316284, 0.5087499618530273, 0.5049999952316284, 0.48499998450279236, 0.543749988079071, 0.48249998688697815, 0.5037499666213989, 0.5049999952316284, 0.4975000023841858, 0.4912499785423279, 0.5149999856948853, 0.5062499642372131, 0.4975000023841858, 0.5037499666213989, 0.5299999713897705, 0.48499998450279236, 0.518750011920929, 0.5237500071525574, 0.4749999940395355, 0.5349999666213989, 0.5099999904632568, 0.5037499666213989, 0.5237500071525574, 0.53125, 0.518750011920929, 0.4975000023841858, 0.4975000023841858, 0.48874998092651367, 0.5174999833106995, 0.5637499690055847, 0.492499977350235, 0.5199999809265137, 0.48874998092651367, 0.4949999749660492, 0.48874998092651367, 0.5249999761581421, 0.4899999797344208, 0.4987500011920929, 0.5012499690055847, 0.5424999594688416, 0.5224999785423279, 0.5062499642372131, 0.5, 0.5174999833106995, 0.518750011920929, 0.4724999964237213, 0.47874999046325684, 0.4699999988079071, 0.48499998450279236, 0.5099999904632568, 0.4987500011920929, 0.5475000143051147, 0.5162500143051147, 0.518750011920929, 0.4987500011920929, 0.5074999928474426, 0.5137500166893005, 0.5087499618530273, 0.5462499856948853, 0.5349999666213989, 0.4962500035762787, 0.4899999797344208, 0.5012499690055847, 0.5112499594688416, 0.5, 0.5112499594688416, 0.4987500011920929, 0.5362499952316284, 0.48249998688697815, 0.5, 0.4937499761581421, 0.47749999165534973, 0.5099999904632568, 0.4949999749660492, 0.550000011920929, 0.5162500143051147, 0.5, 0.5012499690055847, 0.5099999904632568, 0.5299999713897705, 0.5199999809265137, 0.5049999952316284, 0.5099999904632568, 0.5162500143051147, 0.5162500143051147, 0.5224999785423279, 0.5262500047683716, 0.5087499618530273, 0.48749998211860657, 0.5137500166893005, 0.5224999785423279, 0.512499988079071, 0.5374999642372131, 0.4975000023841858, 0.48749998211860657, 0.4899999797344208, 0.5137500166893005, 0.5462499856948853, 0.48249998688697815, 0.4962500035762787, 0.5062499642372131, 0.5099999904632568, 0.4937499761581421, 0.5024999976158142, 0.5024999976158142, 0.5112499594688416, 0.53125, 0.5487499833106995, 0.4899999797344208, 0.5299999713897705, 0.5249999761581421, 0.5462499856948853, 0.5062499642372131, 0.4987500011920929, 0.5137500166893005, 0.5424999594688416, 0.5037499666213989, 0.518750011920929, 0.5012499690055847, 0.4962500035762787, 0.5537499785423279, 0.48124998807907104, 0.48249998688697815, 0.4962500035762787, 0.4912499785423279, 0.47874999046325684, 0.4650000035762787, 0.4962500035762787, 0.5099999904632568, 0.512499988079071, 0.5137500166893005, 0.5162500143051147, 0.5249999761581421, 0.47749999165534973, 0.5099999904632568, 0.5087499618530273, 0.5049999952316284, 0.48624998331069946, 0.48749998211860657, 0.5012499690055847, 0.5112499594688416, 0.5212500095367432, 0.4749999940395355, 0.5149999856948853, 0.5337499976158142, 0.4737499952316284, 0.5049999952316284, 0.5274999737739563, 0.5024999976158142, 0.5162500143051147, 0.518750011920929, 0.4712499976158142, 0.4737499952316284, 0.5237500071525574, 0.5062499642372131, 0.4975000023841858, 0.5112499594688416, 0.5387499928474426, 0.5112499594688416, 0.5199999809265137, 0.5224999785423279, 0.5224999785423279, 0.47749999165534973, 0.48124998807907104, 0.5462499856948853, 0.492499977350235, 0.45749998092651367, 0.4762499928474426, 0.48749998211860657, 0.4912499785423279, 0.5324999690055847, 0.5149999856948853, 0.5249999761581421, 0.5137500166893005, 0.512499988079071, 0.5062499642372131, 0.5062499642372131, 0.5362499952316284, 0.5037499666213989, 0.5262500047683716, 0.5, 0.512499988079071, 0.4699999988079071, 0.4962500035762787, 0.5324999690055847, 0.5087499618530273, 0.5037499666213989, 0.518750011920929, 0.5112499594688416, 0.5037499666213989, 0.48124998807907104, 0.5037499666213989, 0.512499988079071, 0.4724999964237213, 0.4975000023841858, 0.5249999761581421, 0.5337499976158142, 0.4699999988079071, 0.48749998211860657, 0.5362499952316284, 0.461249977350235, 0.5299999713897705, 0.5062499642372131, 0.5037499666213989, 0.4712499976158142, 0.48249998688697815, 0.5174999833106995, 0.5012499690055847, 0.5037499666213989, 0.5249999761581421, 0.5074999928474426, 0.5212500095367432, 0.4712499976158142, 0.5475000143051147, 0.5324999690055847, 0.4987500011920929, 0.5262500047683716, 0.5349999666213989, 0.4899999797344208, 0.5012499690055847, 0.5062499642372131, 0.5099999904632568, 0.4587499797344208, 0.518750011920929, 0.5037499666213989, 0.5299999713897705, 0.5149999856948853, 0.48374998569488525, 0.48499998450279236, 0.5237500071525574, 0.48124998807907104, 0.5362499952316284, 0.5237500071525574, 0.5224999785423279, 0.5412499904632568, 0.5037499666213989, 0.5037499666213989, 0.5012499690055847, 0.492499977350235, 0.4987500011920929, 0.48499998450279236, 0.5137500166893005, 0.4699999988079071, 0.5199999809265137, 0.5024999976158142], 'validation_accuracy': [0.47999998927116394, 0.47999998927116394, 0.4599999785423279, 0.4650000035762787, 0.4949999749660492, 0.4599999785423279, 0.5249999761581421, 0.5149999856948853, 0.5049999952316284, 0.4599999785423279, 0.4949999749660492, 0.5099999904632568, 0.5, 0.5099999904632568, 0.5399999618530273, 0.5600000023841858, 0.5399999618530273, 0.5849999785423279, 0.6150000095367432, 0.6150000095367432, 0.5999999642372131, 0.5399999618530273, 0.5, 0.4949999749660492, 0.5049999952316284, 0.5399999618530273, 0.5049999952316284, 0.5049999952316284, 0.5149999856948853, 0.4949999749660492, 0.4599999785423279, 0.4899999797344208, 0.4899999797344208, 0.48499998450279236, 0.5149999856948853, 0.5299999713897705, 0.5199999809265137, 0.48499998450279236, 0.48499998450279236, 0.4749999940395355, 0.4899999797344208, 0.5, 0.5149999856948853, 0.5299999713897705, 0.5049999952316284, 0.47999998927116394, 0.47999998927116394, 0.48499998450279236, 0.5349999666213989, 0.5399999618530273, 0.5099999904632568, 0.5299999713897705, 0.5349999666213989, 0.5099999904632568, 0.5199999809265137, 0.5249999761581421, 0.47999998927116394, 0.4949999749660492, 0.5249999761581421, 0.5399999618530273, 0.5049999952316284, 0.4650000035762787, 0.4449999928474426, 0.5149999856948853, 0.4749999940395355, 0.45499998331069946, 0.5, 0.5, 0.5049999952316284, 0.5099999904632568, 0.5199999809265137, 0.5149999856948853, 0.5299999713897705, 0.48499998450279236, 0.4899999797344208, 0.5049999952316284, 0.4899999797344208, 0.48499998450279236, 0.4949999749660492, 0.5349999666213989, 0.5399999618530273, 0.5399999618530273, 0.5299999713897705, 0.5299999713897705, 0.5149999856948853, 0.5149999856948853, 0.4949999749660492, 0.4699999988079071, 0.5, 0.5099999904632568, 0.5199999809265137, 0.5349999666213989, 0.5349999666213989, 0.5049999952316284, 0.5899999737739563, 0.5600000023841858, 0.5550000071525574, 0.5149999856948853, 0.5199999809265137, 0.5199999809265137, 0.4949999749660492, 0.5149999856948853, 0.4749999940395355, 0.5099999904632568, 0.4899999797344208, 0.5149999856948853, 0.5099999904632568, 0.44999998807907104, 0.4749999940395355, 0.4699999988079071, 0.5249999761581421, 0.5, 0.4899999797344208, 0.4949999749660492, 0.4899999797344208, 0.5149999856948853, 0.5049999952316284, 0.5600000023841858, 0.5299999713897705, 0.5199999809265137, 0.550000011920929, 0.5199999809265137, 0.5199999809265137, 0.5049999952316284, 0.5049999952316284, 0.5099999904632568, 0.4949999749660492, 0.4449999928474426, 0.41999998688697815, 0.5099999904632568, 0.5099999904632568, 0.5550000071525574, 0.4899999797344208, 0.5649999976158142, 0.5349999666213989, 0.5249999761581421, 0.5550000071525574, 0.4899999797344208, 0.4899999797344208, 0.5049999952316284, 0.5049999952316284, 0.5049999952316284, 0.5199999809265137, 0.5, 0.4949999749660492, 0.47999998927116394, 0.5049999952316284, 0.5349999666213989, 0.4650000035762787, 0.4650000035762787, 0.5399999618530273, 0.5249999761581421, 0.5149999856948853, 0.5349999666213989, 0.5550000071525574, 0.5949999690055847, 0.5699999928474426, 0.5199999809265137, 0.5099999904632568, 0.4749999940395355, 0.45499998331069946, 0.5149999856948853, 0.5, 0.4699999988079071, 0.4599999785423279, 0.5149999856948853, 0.5049999952316284, 0.5149999856948853, 0.4949999749660492, 0.4899999797344208, 0.5399999618530273, 0.5249999761581421, 0.4899999797344208, 0.47999998927116394, 0.5199999809265137, 0.5199999809265137, 0.48499998450279236, 0.5049999952316284, 0.5199999809265137, 0.5, 0.47999998927116394, 0.4749999940395355, 0.5550000071525574, 0.5299999713897705, 0.47999998927116394, 0.5199999809265137, 0.5450000166893005, 0.5049999952316284, 0.5199999809265137, 0.5049999952316284, 0.5099999904632568, 0.5149999856948853, 0.5600000023841858, 0.5550000071525574, 0.5399999618530273, 0.5299999713897705, 0.5249999761581421, 0.5299999713897705, 0.5, 0.5049999952316284, 0.5199999809265137, 0.5049999952316284, 0.4599999785423279, 0.4599999785423279, 0.5099999904632568, 0.5099999904632568, 0.5199999809265137, 0.5, 0.4899999797344208, 0.5550000071525574, 0.5149999856948853, 0.5299999713897705, 0.5099999904632568, 0.5049999952316284, 0.4949999749660492, 0.5149999856948853, 0.5049999952316284, 0.4899999797344208, 0.4599999785423279, 0.5099999904632568, 0.5149999856948853, 0.5399999618530273, 0.48499998450279236, 0.5550000071525574, 0.5349999666213989, 0.5249999761581421, 0.5999999642372131, 0.5049999952316284, 0.5249999761581421, 0.5199999809265137, 0.48499998450279236, 0.4949999749660492, 0.5199999809265137, 0.5299999713897705, 0.47999998927116394, 0.5649999976158142, 0.5600000023841858, 0.5299999713897705, 0.5149999856948853, 0.5149999856948853, 0.5099999904632568, 0.5699999928474426, 0.5299999713897705, 0.5349999666213989, 0.48499998450279236, 0.5550000071525574, 0.5399999618530273, 0.5249999761581421, 0.4949999749660492, 0.4650000035762787, 0.5099999904632568, 0.5249999761581421, 0.5, 0.5799999833106995, 0.5099999904632568, 0.5149999856948853, 0.4899999797344208, 0.4749999940395355, 0.42499998211860657, 0.5049999952316284, 0.5, 0.4749999940395355, 0.48499998450279236, 0.4899999797344208, 0.5199999809265137, 0.47999998927116394, 0.48499998450279236, 0.5299999713897705, 0.5399999618530273, 0.4899999797344208, 0.48499998450279236, 0.5099999904632568, 0.5199999809265137, 0.4899999797344208, 0.48499998450279236, 0.47999998927116394, 0.5099999904632568, 0.5149999856948853, 0.4949999749660492, 0.4949999749660492, 0.4650000035762787, 0.5099999904632568, 0.5, 0.4949999749660492, 0.47999998927116394, 0.5099999904632568, 0.5550000071525574, 0.4949999749660492, 0.5149999856948853, 0.5149999856948853, 0.5399999618530273, 0.48499998450279236, 0.48499998450279236, 0.5249999761581421, 0.5199999809265137, 0.47999998927116394, 0.48499998450279236, 0.5099999904632568, 0.5149999856948853, 0.5699999928474426, 0.574999988079071, 0.5450000166893005, 0.5249999761581421, 0.5199999809265137, 0.47999998927116394, 0.47999998927116394, 0.5199999809265137, 0.5049999952316284, 0.48499998450279236, 0.4749999940395355, 0.5349999666213989, 0.5299999713897705, 0.4899999797344208, 0.4899999797344208, 0.5399999618530273, 0.5149999856948853, 0.4949999749660492, 0.4899999797344208, 0.48499998450279236, 0.5, 0.5], 'final_training_loss': 0.5102556347846985, 'final_training_accuracy': 0.9962499737739563, 'final_validation_loss': 0.6060281991958618, 'final_validation_accuracy': 0.8199999928474426}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(exp_eval_robustness)\n",
    "importlib.reload(exp_train)\n",
    "data_params = dict(\n",
    "    graph_model = 'CSBM',\n",
    "    classes = 2,\n",
    "    n = 1000,\n",
    "    n_per_class_trn = 400,\n",
    "    K = 0.1,\n",
    "    sigma = 1,\n",
    "    avg_within_class_degree = 1.58 * 2,\n",
    "    avg_between_class_degree = 0.37 * 2,\n",
    "    inductive_samples = 100\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"GAT\",\n",
    "    n_filter=64,\n",
    "    n_heads=8,\n",
    "    n_features_per_head=8,\n",
    "    droput=0.0,\n",
    "    droput_neighbourhood=0.0,\n",
    "    use_label_propagation=True,\n",
    "    lp_layers=50,\n",
    "    lp_alpha=0.8,\n",
    "    lp_use_clamping=True\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    lr=1e-1,\n",
    "    weight_decay=1e-4,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "\n",
    "attack_params = dict(\n",
    "    attack = \"random\"\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    display_steps = 100,\n",
    "    debug_lvl = \"info\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = 0,\n",
    "    allow_tf32 = False,\n",
    "    sacred_metrics = True\n",
    ")\n",
    "\n",
    "seed = 0\n",
    "\n",
    "#result = exp_train.run(data_params, model_params, train_params, verbosity_params, other_params, seed, None)\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "a[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUBLAS_WORKSPACE_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3778094/1329080253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUBLAS_WORKSPACE_CONFIG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CUBLAS_WORKSPACE_CONFIG'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 14:11:26 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-08-10 14:11:26 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 0.5, 'sigma': 1, 'avg_within_class_degree': 3.0, 'avg_between_class_degree': 1.0, 'inductive_samples': 1000}\n",
      "2022-08-10 14:11:26 (INFO): model_params: {'label': 'GCN', 'model': 'DenseGCN', 'n_filters': 64}\n",
      "2022-08-10 14:11:26 (INFO): train_params: {'lr': 0.01, 'weight_decay': 0.001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-08-10 14:11:26 (INFO): attack_params: {'attack': 'l2'}\n",
      "2022-08-10 14:11:26 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-08-10 14:11:26 (INFO): other_params: {'device': 0, 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-08-10 14:11:26 (INFO): seed: 1\n",
      "2022-08-10 14:11:26 (INFO): db_collection: None\n",
      "2022-08-10 14:11:26 (INFO): Currently on gpu device cuda:0\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch    0: loss_train: 0.70102, loss_val: 0.69805, acc_train: 0.47250, acc_val: 0.49500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  100: loss_train: 0.41914, loss_val: 0.58875, acc_train: 0.80500, acc_val: 0.68500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  200: loss_train: 0.41618, loss_val: 0.60138, acc_train: 0.80000, acc_val: 0.70000\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch  300: loss_train: 0.40287, loss_val: 0.60636, acc_train: 0.81750, acc_val: 0.68500\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch   66: loss_train: 0.47474, loss_val: 0.58023, acc_train: 0.77750, acc_val: 0.68500\n",
      "2022-08-10 14:11:50 (INFO): Prediction Statistics:\n",
      "2022-08-10 14:11:50 (INFO): Count BC: 861.0 GNN: 694.0\n",
      "2022-08-10 14:11:50 (INFO): Count Structure BC: 855.0 Feature BC: 590.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC and GNN: 640.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC not GNN: 221.0 GNN not BC: 54.0\n",
      "2022-08-10 14:11:50 (INFO): Robustness Statistics:\n",
      "2022-08-10 14:11:50 (INFO): BC more robust than GNN: 175.0\n",
      "2022-08-10 14:11:50 (INFO): BC & GNN equal robustness: 101.0\n",
      "2022-08-10 14:11:50 (INFO): BC less robust than GNN: 364.0\n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <BC robust>: 0.12; <GNN robust>: 1.17; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <BC robust>: 0.65; <GNN robust>: 2.40; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <BC robust>: 1.17; <GNN robust>: 3.83; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <BC robust>: 1.54; <GNN robust>: 2.71; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <BC robust>: 2.01; <GNN robust>: 4.02; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <BC robust>: 2.73; <GNN robust>: 5.47; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <BC robust>: 2.79; <GNN robust>: 5.42; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <BC robust>: 3.24; <GNN robust>: 6.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <BC robust>: 3.94; <GNN robust>: 6.43; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <BC robust>: 3.45; <GNN robust>: 3.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <BC robust>: 7.80; <GNN robust>: 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Max(BC robust): 1.00; Max(GNN robust): 6.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Max(BC robust): 2.00; Max(GNN robust): 20.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Max(BC robust): 3.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Max(BC robust): 4.00; Max(GNN robust): 17.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Max(BC robust): 5.00; Max(GNN robust): 16.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Max(BC robust): 6.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Max(BC robust): 6.00; Max(GNN robust): 35.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Max(BC robust): 7.00; Max(GNN robust): 33.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Max(BC robust): 8.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Max(BC robust): 7.00; Max(GNN robust): 8.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Max(BC robust): 10.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Median(BC robust): 0.00; Median(GNN robust): 0.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Median(BC robust): 1.00; Median(GNN robust): 1.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Median(BC robust): 2.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Median(BC robust): 4.00; Median(GNN robust): 5.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Median(BC robust): 3.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Median(BC robust): 8.00; Median(GNN robust): 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <GNN wrt BC robust>: 0.17/0.17. <GNN in wrt BC setting>: 1.17\n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <GNN wrt BC robust>: 0.54/0.74. <GNN in wrt BC setting>: 2.64\n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <GNN wrt BC robust>: 0.99/1.25. <GNN in wrt BC setting>: 4.11\n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <GNN wrt BC robust>: 1.12/1.71. <GNN in wrt BC setting>: 2.81\n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <GNN wrt BC robust>: 1.65/2.08. <GNN in wrt BC setting>: 4.12\n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <GNN wrt BC robust>: 2.28/2.98. <GNN in wrt BC setting>: 5.54\n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <GNN wrt BC robust>: 2.46/2.93. <GNN in wrt BC setting>: 5.66\n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <GNN wrt BC robust>: 2.73/3.70. <GNN in wrt BC setting>: 6.27\n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <GNN wrt BC robust>: 3.41/4.19. <GNN in wrt BC setting>: 6.67\n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <GNN wrt BC robust>: 2.11/3.44. <GNN in wrt BC setting>: 3.22\n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <GNN wrt BC robust>: 6.00/7.80. <GNN in wrt BC setting>: 12.00\n"
     ]
    }
   ],
   "source": [
    "data_params[\"sigma\"] = 1\n",
    "seed = 1\n",
    "\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import calc_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 25 25]\n"
     ]
    }
   ],
   "source": [
    "class_counts = [10, 100, 100]\n",
    "n_samples = 60\n",
    "print(calc_balanced_sample(class_counts, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.Tensor([[0.8, 0.2], [0.1, 0.9]])\n",
    "labels = torch.Tensor([0, 1])\n",
    "logits.argmax(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

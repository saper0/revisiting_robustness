{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.graph_models import create_graph_model\n",
    "import numpy as np\n",
    "import torch\n",
    "import exp_eval_robustness\n",
    "import exp_train\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = dict(\n",
    "    graph_model = 'CSBM',\n",
    "    classes = 2,\n",
    "    n = 1000,\n",
    "    n_per_class_trn = 400,\n",
    "    K = 1,\n",
    "    sigma = 1,\n",
    "    avg_within_class_degree = 1.58 * 2,\n",
    "    avg_between_class_degree = 0.37 * 2,\n",
    "    inductive_samples = 100,\n",
    "    m=2,\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"DenseGCN\",\n",
    "    n_filters=64,\n",
    "    dropout=0.5,\n",
    "    use_label_propagation=False,\n",
    "    #LP\n",
    "    #lp_layers=50,\n",
    "    #lp_alpha=0.7,\n",
    "    #lp_use_clamping=False,\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-4,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "\n",
    "attack_params = dict(\n",
    "    attack = \"SGA\",\n",
    "    max_robustness = 10,\n",
    "    surrogate_model_params = dict(\n",
    "        label=\"LinearGCN\",\n",
    "        model=\"LinearGCN\",\n",
    "        n_filter=64,\n",
    "        dropout=0.5,\n",
    "    ),\n",
    "    surrogate_train_params = dict(\n",
    "        lr=0.1,\n",
    "        weight_decay=1e-4,\n",
    "        patience=300,\n",
    "        max_epochs=3000,\n",
    "    ),\n",
    "    power_law_test=True,\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    display_steps = 100,\n",
    "    debug_lvl = \"info\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = \"cpu\",\n",
    "    allow_tf32 = False,\n",
    "    sacred_metrics = True\n",
    ")\n",
    "\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 20:57:21 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-11-08 20:57:21 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 1, 'sigma': 1, 'avg_within_class_degree': 3.16, 'avg_between_class_degree': 0.74, 'inductive_samples': 100, 'm': 2}\n",
      "2022-11-08 20:57:21 (INFO): model_params: {'label': 'GCN', 'model': 'DenseGCN', 'n_filters': 64, 'dropout': 0.5, 'use_label_propagation': False}\n",
      "2022-11-08 20:57:21 (INFO): train_params: {'lr': 0.1, 'weight_decay': 0.0001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-11-08 20:57:21 (INFO): attack_params: {'attack': 'SGA', 'max_robustness': 10, 'surrogate_model_params': {'label': 'LinearGCN', 'model': 'LinearGCN', 'n_filter': 64, 'dropout': 0.5}, 'surrogate_train_params': {'lr': 0.1, 'weight_decay': 0.0001, 'patience': 300, 'max_epochs': 3000}, 'power_law_test': True}\n",
      "2022-11-08 20:57:21 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-11-08 20:57:21 (INFO): other_params: {'device': 'cpu', 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-11-08 20:57:21 (INFO): seed: 8\n",
      "2022-11-08 20:57:21 (INFO): db_collection: None\n",
      "2022-11-08 20:57:22 (INFO): \n",
      "Epoch    0: loss_train: 0.68989, loss_val: 0.70425, acc_train: 0.56250, acc_val: 0.42500\n",
      "2022-11-08 20:57:24 (INFO): \n",
      "Epoch  100: loss_train: 0.30319, loss_val: 0.36770, acc_train: 0.87750, acc_val: 0.84500\n",
      "2022-11-08 20:57:26 (INFO): \n",
      "Epoch  200: loss_train: 0.27201, loss_val: 0.38457, acc_train: 0.88500, acc_val: 0.81500\n",
      "2022-11-08 20:57:29 (INFO): \n",
      "Epoch  300: loss_train: 0.25098, loss_val: 0.37166, acc_train: 0.90750, acc_val: 0.83000\n",
      "2022-11-08 20:57:29 (INFO): \n",
      "Epoch   14: loss_train: 0.37303, loss_val: 0.32159, acc_train: 0.85375, acc_val: 0.83500\n",
      "2022-11-08 20:57:29 (INFO): \n",
      "Epoch    0: loss_train: 0.72243, loss_val: 0.70282, acc_train: 0.40125, acc_val: 0.46500\n",
      "2022-11-08 20:57:32 (INFO): \n",
      "Epoch  100: loss_train: 0.44463, loss_val: 0.35530, acc_train: 0.81125, acc_val: 0.84000\n",
      "2022-11-08 20:57:36 (INFO): \n",
      "Epoch  200: loss_train: 0.44256, loss_val: 0.36120, acc_train: 0.81500, acc_val: 0.84000\n",
      "2022-11-08 20:57:39 (INFO): \n",
      "Epoch  300: loss_train: 0.48077, loss_val: 0.37310, acc_train: 0.80750, acc_val: 0.81000\n",
      "2022-11-08 20:57:39 (INFO): \n",
      "Epoch   14: loss_train: 0.46856, loss_val: 0.33328, acc_train: 0.80625, acc_val: 0.84000\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.54it/s]\n",
      "2022-11-08 20:57:48 (INFO): Prediction Statistics:\n",
      "2022-11-08 20:57:48 (INFO): Count BC: 91.0 GNN: 86.0\n",
      "2022-11-08 20:57:48 (INFO): Count Structure BC: 86.0 Feature BC: 74.0\n",
      "2022-11-08 20:57:48 (INFO): Count BC and GNN: 82.0\n",
      "2022-11-08 20:57:48 (INFO): Count BC not GNN: 9.0 GNN not BC: 4.0\n",
      "2022-11-08 20:57:48 (INFO): Robustness Statistics:\n",
      "2022-11-08 20:57:48 (INFO): BC more robust than GNN: 50.0\n",
      "2022-11-08 20:57:48 (INFO): BC & GNN equal robustness: 17.0\n",
      "2022-11-08 20:57:48 (INFO): BC less robust than GNN: 15.0\n",
      "2022-11-08 20:57:48 (INFO): Degree 0: <BC robust>: 0.33; <GNN robust>: 0.25; \n",
      "2022-11-08 20:57:48 (INFO): Degree 1: <BC robust>: 0.71; <GNN robust>: 0.29; \n",
      "2022-11-08 20:57:48 (INFO): Degree 2: <BC robust>: 1.54; <GNN robust>: 0.91; \n",
      "2022-11-08 20:57:48 (INFO): Degree 3: <BC robust>: 2.07; <GNN robust>: 1.54; \n",
      "2022-11-08 20:57:48 (INFO): Degree 4: <BC robust>: 2.52; <GNN robust>: 1.85; \n",
      "2022-11-08 20:57:48 (INFO): Degree 5: <BC robust>: 3.60; <GNN robust>: 2.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 6: <BC robust>: 3.77; <GNN robust>: 1.85; \n",
      "2022-11-08 20:57:48 (INFO): Degree 7: <BC robust>: 4.50; <GNN robust>: 2.50; \n",
      "2022-11-08 20:57:48 (INFO): Degree 8: <BC robust>: 4.00; <GNN robust>: 2.50; \n",
      "2022-11-08 20:57:48 (INFO): Degree 9: <BC robust>: 6.00; <GNN robust>: 3.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 0: Max(BC robust): 1.00; Max(GNN robust): 1.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 1: Max(BC robust): 2.00; Max(GNN robust): 1.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 2: Max(BC robust): 3.00; Max(GNN robust): 3.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 3: Max(BC robust): 4.00; Max(GNN robust): 5.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 4: Max(BC robust): 6.00; Max(GNN robust): 7.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 5: Max(BC robust): 6.00; Max(GNN robust): 7.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 6: Max(BC robust): 7.00; Max(GNN robust): 7.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 7: Max(BC robust): 6.00; Max(GNN robust): 7.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 8: Max(BC robust): 5.00; Max(GNN robust): 4.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 9: Max(BC robust): 6.00; Max(GNN robust): 6.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 0: Median(BC robust): 0.00; Median(GNN robust): 0.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 1: Median(BC robust): 1.00; Median(GNN robust): 0.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 2: Median(BC robust): 2.00; Median(GNN robust): 0.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 3: Median(BC robust): 2.50; Median(GNN robust): 1.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 4: Median(BC robust): 2.00; Median(GNN robust): 1.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 5: Median(BC robust): 4.00; Median(GNN robust): 1.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 6: Median(BC robust): 4.00; Median(GNN robust): 1.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 7: Median(BC robust): 4.50; Median(GNN robust): 1.50; \n",
      "2022-11-08 20:57:48 (INFO): Degree 8: Median(BC robust): 4.00; Median(GNN robust): 2.50; \n",
      "2022-11-08 20:57:48 (INFO): Degree 9: Median(BC robust): 6.00; Median(GNN robust): 3.00; \n",
      "2022-11-08 20:57:48 (INFO): Degree 0: <GNN wrt BC robust>: 0.33/0.33. <GNN in wrt BC setting>: 0.33\n",
      "2022-11-08 20:57:48 (INFO): Degree 1: <GNN wrt BC robust>: 0.17/0.67. <GNN in wrt BC setting>: 0.33\n",
      "2022-11-08 20:57:48 (INFO): Degree 2: <GNN wrt BC robust>: 0.73/1.64. <GNN in wrt BC setting>: 0.91\n",
      "2022-11-08 20:57:48 (INFO): Degree 3: <GNN wrt BC robust>: 0.92/2.00. <GNN in wrt BC setting>: 1.54\n",
      "2022-11-08 20:57:48 (INFO): Degree 4: <GNN wrt BC robust>: 1.42/2.79. <GNN in wrt BC setting>: 1.89\n",
      "2022-11-08 20:57:48 (INFO): Degree 5: <GNN wrt BC robust>: 1.70/3.60. <GNN in wrt BC setting>: 2.00\n",
      "2022-11-08 20:57:48 (INFO): Degree 6: <GNN wrt BC robust>: 1.83/4.00. <GNN in wrt BC setting>: 2.00\n",
      "2022-11-08 20:57:48 (INFO): Degree 7: <GNN wrt BC robust>: 2.25/4.50. <GNN in wrt BC setting>: 2.50\n",
      "2022-11-08 20:57:48 (INFO): Degree 8: <GNN wrt BC robust>: 2.00/4.00. <GNN in wrt BC setting>: 2.50\n",
      "2022-11-08 20:57:48 (INFO): Degree 9: <GNN wrt BC robust>: 3.00/6.00. <GNN in wrt BC setting>: 3.00\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(exp_eval_robustness)\n",
    "importlib.reload(exp_train)\n",
    "#result = exp_train.run(data_params, model_params, train_params, verbosity_params, other_params, seed, None)\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-08 16:00:42 (INFO): \n",
      "Epoch    0: loss_train: 0.74230, loss_val: 0.74731, acc_train: 0.32375, acc_val: 0.23500\n",
      "2022-11-08 16:00:42 (INFO): \n",
      "Epoch  100: loss_train: 0.21736, loss_val: 0.27384, acc_train: 0.91625, acc_val: 0.89500\n",
      "2022-11-08 16:00:43 (INFO): \n",
      "Epoch  200: loss_train: 0.21414, loss_val: 0.27090, acc_train: 0.92000, acc_val: 0.89500\n",
      "2022-11-08 16:00:43 (INFO): \n",
      "Epoch  300: loss_train: 0.20504, loss_val: 0.27502, acc_train: 0.91625, acc_val: 0.89000\n",
      "2022-11-08 16:00:44 (INFO): \n",
      "Epoch  400: loss_train: 0.21400, loss_val: 0.26903, acc_train: 0.91125, acc_val: 0.90500\n",
      "2022-11-08 16:00:44 (INFO): \n",
      "Epoch  500: loss_train: 0.21238, loss_val: 0.27094, acc_train: 0.91125, acc_val: 0.90000\n",
      "2022-11-08 16:00:44 (INFO): \n",
      "Epoch  600: loss_train: 0.21301, loss_val: 0.26617, acc_train: 0.92375, acc_val: 0.89500\n",
      "2022-11-08 16:00:45 (INFO): \n",
      "Epoch  366: loss_train: 0.22549, loss_val: 0.24665, acc_train: 0.90500, acc_val: 0.90500\n"
     ]
    }
   ],
   "source": [
    "from src.data import split\n",
    "from src.models import create_model\n",
    "from src.train import train_inductive, train_transductive\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"LinearGCN\",\n",
    "    n_filter=64,\n",
    "    dropout=0.5,\n",
    "    use_label_propagation=False,\n",
    ")\n",
    "train_params = dict(\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-3,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "_run = None\n",
    "device = torch.device(f\"cuda:{0}\")\n",
    "\n",
    "# Sample Graph\n",
    "graph_model = create_graph_model(data_params)\n",
    "X_np, A_np, y_np = graph_model.sample(data_params[\"n\"], seed)\n",
    "X = torch.tensor(X_np, dtype=torch.float32, device=device)\n",
    "A = torch.tensor(A_np, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y_np, device=device)\n",
    "split_trn, split_val = split(y_np, data_params)\n",
    "\n",
    "# Create Model\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=X_np.shape[1], \n",
    "                        n_classes=data_params[\"classes\"])\n",
    "model = create_model(model_params_trn).to(device)\n",
    "#logging.info(model)\n",
    "\n",
    "# Train Model\n",
    "if train_params[\"inductive\"]:\n",
    "    train = train_inductive\n",
    "else:\n",
    "    train = train_transductive\n",
    "trn_tracker = train(model, None, X, A, y, split_trn, split_val, train_params,\n",
    "                    verbosity_params, _run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 64])\n",
      "torch.Size([64, 2])\n",
      "torch.Size([21, 2])\n"
     ]
    }
   ],
   "source": [
    "W1 = model.layers[0][0]._linear.weight.T\n",
    "W2 = model.layers[1][0]._linear.weight.T\n",
    "print(W1.shape)\n",
    "print(W2.shape)\n",
    "print(W1.matmul(W2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseGCN(\n",
      "  (activation): Identity()\n",
      "  (layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (gcn_0): DenseGraphConvolution(\n",
      "        (_linear): Linear(in_features=21, out_features=64, bias=False)\n",
      "      )\n",
      "      (activation_0): Identity()\n",
      "      (dropout_0): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (gcn_1): DenseGraphConvolution(\n",
      "        (_linear): Linear(in_features=64, out_features=2, bias=False)\n",
      "      )\n",
      "      (softmax_1): LogSoftmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.gcn import DenseGCN\n",
    "isinstance(model, DenseGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model.activation, torch.nn.Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2845, -0.1751,  0.0541,  ...,  0.3195,  0.0939,  0.0529],\n",
       "        [-0.0133, -0.1708,  0.0041,  ..., -0.0677, -0.3852, -0.0863],\n",
       "        [ 0.0237, -0.1400,  0.0761,  ..., -0.0926, -0.1117, -0.0352],\n",
       "        ...,\n",
       "        [-0.1547, -0.6180,  0.0105,  ..., -0.4443, -0.1026, -0.1262],\n",
       "        [-0.0155,  0.1586,  0.4082,  ...,  0.2353, -0.1754, -0.0009],\n",
       "        [-0.1066, -0.2037, -0.0348,  ..., -0.1079, -0.1091, -0.2001]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0][0]._linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    label=\"SGC\",\n",
    "    model=\"SGC\",\n",
    "    K=2,\n",
    "    use_label_propagation=False,\n",
    ")\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=X_np.shape[1], \n",
    "                        n_classes=data_params[\"classes\"])\n",
    "sgc = create_model(model_params_trn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseGraphConvolution(\n",
       "  (_linear): Linear(in_features=21, out_features=64, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SGC(\n",
       "  (sgc): SGConv(21, 2, K=2)\n",
       ")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgc.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(10):\n",
    "        yield i\n",
    "    yield None\n",
    "\n",
    "\n",
    "mygen = gen()\n",
    "def call_gen():\n",
    "    return next(mygen)\n",
    "\n",
    "for i in range(11):\n",
    "    print(call_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUBLAS_WORKSPACE_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3778094/1329080253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUBLAS_WORKSPACE_CONFIG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CUBLAS_WORKSPACE_CONFIG'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 14:11:26 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-08-10 14:11:26 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 0.5, 'sigma': 1, 'avg_within_class_degree': 3.0, 'avg_between_class_degree': 1.0, 'inductive_samples': 1000}\n",
      "2022-08-10 14:11:26 (INFO): model_params: {'label': 'GCN', 'model': 'DenseGCN', 'n_filters': 64}\n",
      "2022-08-10 14:11:26 (INFO): train_params: {'lr': 0.01, 'weight_decay': 0.001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-08-10 14:11:26 (INFO): attack_params: {'attack': 'l2'}\n",
      "2022-08-10 14:11:26 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-08-10 14:11:26 (INFO): other_params: {'device': 0, 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-08-10 14:11:26 (INFO): seed: 1\n",
      "2022-08-10 14:11:26 (INFO): db_collection: None\n",
      "2022-08-10 14:11:26 (INFO): Currently on gpu device cuda:0\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch    0: loss_train: 0.70102, loss_val: 0.69805, acc_train: 0.47250, acc_val: 0.49500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  100: loss_train: 0.41914, loss_val: 0.58875, acc_train: 0.80500, acc_val: 0.68500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  200: loss_train: 0.41618, loss_val: 0.60138, acc_train: 0.80000, acc_val: 0.70000\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch  300: loss_train: 0.40287, loss_val: 0.60636, acc_train: 0.81750, acc_val: 0.68500\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch   66: loss_train: 0.47474, loss_val: 0.58023, acc_train: 0.77750, acc_val: 0.68500\n",
      "2022-08-10 14:11:50 (INFO): Prediction Statistics:\n",
      "2022-08-10 14:11:50 (INFO): Count BC: 861.0 GNN: 694.0\n",
      "2022-08-10 14:11:50 (INFO): Count Structure BC: 855.0 Feature BC: 590.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC and GNN: 640.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC not GNN: 221.0 GNN not BC: 54.0\n",
      "2022-08-10 14:11:50 (INFO): Robustness Statistics:\n",
      "2022-08-10 14:11:50 (INFO): BC more robust than GNN: 175.0\n",
      "2022-08-10 14:11:50 (INFO): BC & GNN equal robustness: 101.0\n",
      "2022-08-10 14:11:50 (INFO): BC less robust than GNN: 364.0\n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <BC robust>: 0.12; <GNN robust>: 1.17; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <BC robust>: 0.65; <GNN robust>: 2.40; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <BC robust>: 1.17; <GNN robust>: 3.83; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <BC robust>: 1.54; <GNN robust>: 2.71; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <BC robust>: 2.01; <GNN robust>: 4.02; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <BC robust>: 2.73; <GNN robust>: 5.47; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <BC robust>: 2.79; <GNN robust>: 5.42; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <BC robust>: 3.24; <GNN robust>: 6.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <BC robust>: 3.94; <GNN robust>: 6.43; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <BC robust>: 3.45; <GNN robust>: 3.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <BC robust>: 7.80; <GNN robust>: 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Max(BC robust): 1.00; Max(GNN robust): 6.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Max(BC robust): 2.00; Max(GNN robust): 20.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Max(BC robust): 3.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Max(BC robust): 4.00; Max(GNN robust): 17.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Max(BC robust): 5.00; Max(GNN robust): 16.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Max(BC robust): 6.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Max(BC robust): 6.00; Max(GNN robust): 35.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Max(BC robust): 7.00; Max(GNN robust): 33.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Max(BC robust): 8.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Max(BC robust): 7.00; Max(GNN robust): 8.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Max(BC robust): 10.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Median(BC robust): 0.00; Median(GNN robust): 0.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Median(BC robust): 1.00; Median(GNN robust): 1.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Median(BC robust): 2.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Median(BC robust): 4.00; Median(GNN robust): 5.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Median(BC robust): 3.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Median(BC robust): 8.00; Median(GNN robust): 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <GNN wrt BC robust>: 0.17/0.17. <GNN in wrt BC setting>: 1.17\n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <GNN wrt BC robust>: 0.54/0.74. <GNN in wrt BC setting>: 2.64\n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <GNN wrt BC robust>: 0.99/1.25. <GNN in wrt BC setting>: 4.11\n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <GNN wrt BC robust>: 1.12/1.71. <GNN in wrt BC setting>: 2.81\n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <GNN wrt BC robust>: 1.65/2.08. <GNN in wrt BC setting>: 4.12\n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <GNN wrt BC robust>: 2.28/2.98. <GNN in wrt BC setting>: 5.54\n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <GNN wrt BC robust>: 2.46/2.93. <GNN in wrt BC setting>: 5.66\n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <GNN wrt BC robust>: 2.73/3.70. <GNN in wrt BC setting>: 6.27\n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <GNN wrt BC robust>: 3.41/4.19. <GNN in wrt BC setting>: 6.67\n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <GNN wrt BC robust>: 2.11/3.44. <GNN in wrt BC setting>: 3.22\n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <GNN wrt BC robust>: 6.00/7.80. <GNN in wrt BC setting>: 12.00\n"
     ]
    }
   ],
   "source": [
    "data_params[\"sigma\"] = 1\n",
    "seed = 1\n",
    "\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import calc_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 25 25]\n"
     ]
    }
   ],
   "source": [
    "class_counts = [10, 100, 100]\n",
    "n_samples = 60\n",
    "print(calc_balanced_sample(class_counts, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.Tensor([[0.8, 0.2], [0.1, 0.9]])\n",
    "labels = torch.Tensor([0, 1])\n",
    "logits.argmax(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

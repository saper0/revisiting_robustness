{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.graph_models import create_graph_model\n",
    "import numpy as np\n",
    "import torch\n",
    "import exp_eval_robustness\n",
    "import exp_train\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = dict(\n",
    "    graph_model = 'CBA',\n",
    "    classes = 2,\n",
    "    n = 1000,\n",
    "    n_per_class_trn = 400,\n",
    "    K = 2,\n",
    "    sigma = 1,\n",
    "    avg_within_class_degree = 1.58 * 2,\n",
    "    avg_between_class_degree = 0.37 * 2,\n",
    "    inductive_samples = 1000,\n",
    "    m=2,\n",
    ")\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"DenseGCN\",\n",
    "    n_filters=64,\n",
    "    dropout=0.5,\n",
    "    use_label_propagation=False,\n",
    "    #LP\n",
    "    #lp_layers=50,\n",
    "    #lp_alpha=0.7,\n",
    "    #lp_use_clamping=False,\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-4,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "\n",
    "attack_params = dict(\n",
    "    attack = \"l2-weak\",\n",
    "    max_robustness = 10,\n",
    "    surrogate_model_params = dict(\n",
    "        label=\"LinearGCN\",\n",
    "        model=\"LinearGCN\",\n",
    "        n_filter=64,\n",
    "        dropout=0.5,\n",
    "    ),\n",
    "    surrogate_train_params = dict(\n",
    "        lr=0.1,\n",
    "        weight_decay=1e-4,\n",
    "        patience=300,\n",
    "        max_epochs=3000,\n",
    "    ),\n",
    "    power_law_test=True,\n",
    ")\n",
    "\n",
    "verbosity_params = dict(\n",
    "    display_steps = 100,\n",
    "    debug_lvl = \"info\"\n",
    ")  \n",
    "\n",
    "other_params = dict(\n",
    "    device = 0,\n",
    "    allow_tf32 = False,\n",
    "    sacred_metrics = True\n",
    ")\n",
    "\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 16:36:21 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-11-07 16:36:21 (INFO): data_params: {'graph_model': 'CBA', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 2, 'sigma': 1, 'avg_within_class_degree': 3.16, 'avg_between_class_degree': 0.74, 'inductive_samples': 1000, 'm': 2}\n",
      "2022-11-07 16:36:21 (INFO): model_params: {'label': 'GCN', 'model': 'DenseGCN', 'n_filters': 64, 'dropout': 0.5, 'use_label_propagation': False}\n",
      "2022-11-07 16:36:21 (INFO): train_params: {'lr': 0.1, 'weight_decay': 0.0001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-11-07 16:36:21 (INFO): attack_params: {'attack': 'l2-weak', 'max_robustness': 10, 'surrogate_model_params': {'label': 'LinearGCN', 'model': 'LinearGCN', 'n_filter': 64, 'dropout': 0.5}, 'surrogate_train_params': {'lr': 0.1, 'weight_decay': 0.0001, 'patience': 300, 'max_epochs': 3000}, 'power_law_test': True}\n",
      "2022-11-07 16:36:21 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-11-07 16:36:21 (INFO): other_params: {'device': 0, 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-11-07 16:36:21 (INFO): seed: 8\n",
      "2022-11-07 16:36:21 (INFO): db_collection: None\n",
      "2022-11-07 16:36:21 (INFO): Currently on gpu device cuda:0\n",
      "2022-11-07 16:36:26 (INFO): \n",
      "Epoch    0: loss_train: 0.70147, loss_val: 0.69359, acc_train: 0.48000, acc_val: 0.49500\n",
      "2022-11-07 16:36:27 (INFO): \n",
      "Epoch  100: loss_train: 0.12127, loss_val: 0.34796, acc_train: 0.94875, acc_val: 0.90000\n",
      "2022-11-07 16:36:27 (INFO): \n",
      "Epoch  200: loss_train: 0.15032, loss_val: 0.42495, acc_train: 0.93750, acc_val: 0.90500\n",
      "2022-11-07 16:36:28 (INFO): \n",
      "Epoch  300: loss_train: 0.12183, loss_val: 0.38364, acc_train: 0.95250, acc_val: 0.90000\n",
      "2022-11-07 16:36:28 (INFO): \n",
      "Epoch    2: loss_train: 0.22455, loss_val: 0.28466, acc_train: 0.91125, acc_val: 0.89500\n",
      "  4%|‚ñç         | 40/1000 [00:03<01:32, 10.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2867785/3202882534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#result = exp_train.run(data_params, model_params, train_params, verbosity_params, other_params, seed, None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_eval_robustness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/sacred/config/captured_function.py\u001b[0m in \u001b[0;36mcaptured_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# =================== run actual function =================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mConfigError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m# =========================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/exp_eval_robustness.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, db_collection, _run)\u001b[0m\n\u001b[1;32m    300\u001b[0m               surrogate_train_params, verbosity_params, _run)\n\u001b[1;32m    301\u001b[0m         \u001b[0msurrogate_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     results_dict = evaluate_robustness(model, \n\u001b[0m\u001b[1;32m    303\u001b[0m                                        \u001b[0mlabel_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                        \u001b[0mgraph_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/eval.py\u001b[0m in \u001b[0;36mevaluate_robustness\u001b[0;34m(model, label_prop, graph_model, X_np, A_np, y_np, inductive_samples, attack_params, surrogate_model, device)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Robustness of BC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbayes_separable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 bayes_separable_new, _ = graph_model.likelihood_separability(\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 )\n",
      "\u001b[0;32m~/src/csbm/src/graph_models/cba.py\u001b[0m in \u001b[0;36mlikelihood_separability\u001b[0;34m(self, X, A, y, ids)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mn_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mn_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mlikelihood_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mlikelihood_wrong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlikelihood_corr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlikelihood_wrong\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/graph_models/cba.py\u001b[0m in \u001b[0;36mloglikelihood\u001b[0;34m(self, n_id, n_cls, X, A, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                                       \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_cls\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                                       cov=self.cov))\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mlikelihood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure_loglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/csbm/src/graph_models/cba.py\u001b[0m in \u001b[0;36mstructure_loglikelihood\u001b[0;34m(self, n_id, n_cls, A, y)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m#### Calculate Drawing Probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Correct for new edges from n_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2248\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(exp_eval_robustness)\n",
    "importlib.reload(exp_train)\n",
    "#result = exp_train.run(data_params, model_params, train_params, verbosity_params, other_params, seed, None)\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-06 14:57:49 (INFO): \n",
      "Epoch    0: loss_train: 0.70049, loss_val: 0.69125, acc_train: 0.51250, acc_val: 0.54000\n",
      "2022-09-06 14:57:49 (INFO): \n",
      "Epoch  100: loss_train: 0.66957, loss_val: 0.70510, acc_train: 0.59875, acc_val: 0.55000\n",
      "2022-09-06 14:57:50 (INFO): \n",
      "Epoch  200: loss_train: 0.69992, loss_val: 0.69783, acc_train: 0.57000, acc_val: 0.59000\n",
      "2022-09-06 14:57:50 (INFO): \n",
      "Epoch  300: loss_train: 0.67012, loss_val: 0.70146, acc_train: 0.59500, acc_val: 0.53000\n",
      "2022-09-06 14:57:51 (INFO): \n",
      "Epoch  400: loss_train: 0.67534, loss_val: 0.70552, acc_train: 0.57750, acc_val: 0.53000\n",
      "2022-09-06 14:57:51 (INFO): \n",
      "Epoch  500: loss_train: 0.69036, loss_val: 0.70550, acc_train: 0.58875, acc_val: 0.53500\n",
      "2022-09-06 14:57:51 (INFO): \n",
      "Epoch  600: loss_train: 0.67120, loss_val: 0.70989, acc_train: 0.60250, acc_val: 0.53000\n",
      "2022-09-06 14:57:52 (INFO): \n",
      "Epoch  700: loss_train: 0.68360, loss_val: 0.70071, acc_train: 0.56875, acc_val: 0.53500\n",
      "2022-09-06 14:57:52 (INFO): \n",
      "Epoch  430: loss_train: 0.67145, loss_val: 0.68283, acc_train: 0.59750, acc_val: 0.58500\n"
     ]
    }
   ],
   "source": [
    "from src.data import split\n",
    "from src.models import create_model\n",
    "from src.train import train_inductive, train_transductive\n",
    "\n",
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"LinearGCN\",\n",
    "    n_filter=64,\n",
    "    dropout=0.5,\n",
    "    use_label_propagation=False,\n",
    ")\n",
    "train_params = dict(\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-3,\n",
    "    patience=300,\n",
    "    max_epochs=3000,\n",
    "    inductive=True,\n",
    ")\n",
    "_run = None\n",
    "device = torch.device(f\"cuda:{0}\")\n",
    "\n",
    "# Sample Graph\n",
    "graph_model = create_graph_model(data_params)\n",
    "X_np, A_np, y_np = graph_model.sample(data_params[\"n\"], seed)\n",
    "X = torch.tensor(X_np, dtype=torch.float32, device=device)\n",
    "A = torch.tensor(A_np, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y_np, device=device)\n",
    "split_trn, split_val = split(y_np, data_params)\n",
    "\n",
    "# Create Model\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=X_np.shape[1], \n",
    "                        n_classes=data_params[\"classes\"])\n",
    "model = create_model(model_params_trn).to(device)\n",
    "#logging.info(model)\n",
    "\n",
    "# Train Model\n",
    "if train_params[\"inductive\"]:\n",
    "    train = train_inductive\n",
    "else:\n",
    "    train = train_transductive\n",
    "trn_tracker = train(model, None, X, A, y, split_trn, split_val, train_params,\n",
    "                    verbosity_params, _run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.models.gcn.DenseGCN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.gcn import DenseGCN\n",
    "isinstance(model, DenseGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model.activation, torch.nn.Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2845, -0.1751,  0.0541,  ...,  0.3195,  0.0939,  0.0529],\n",
       "        [-0.0133, -0.1708,  0.0041,  ..., -0.0677, -0.3852, -0.0863],\n",
       "        [ 0.0237, -0.1400,  0.0761,  ..., -0.0926, -0.1117, -0.0352],\n",
       "        ...,\n",
       "        [-0.1547, -0.6180,  0.0105,  ..., -0.4443, -0.1026, -0.1262],\n",
       "        [-0.0155,  0.1586,  0.4082,  ...,  0.2353, -0.1754, -0.0009],\n",
       "        [-0.1066, -0.2037, -0.0348,  ..., -0.1079, -0.1091, -0.2001]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0][0]._linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    label=\"SGC\",\n",
    "    model=\"SGC\",\n",
    "    K=2,\n",
    "    use_label_propagation=False,\n",
    ")\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=X_np.shape[1], \n",
    "                        n_classes=data_params[\"classes\"])\n",
    "sgc = create_model(model_params_trn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseGraphConvolution(\n",
       "  (_linear): Linear(in_features=21, out_features=64, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SGC(\n",
       "  (sgc): SGConv(21, 2, K=2)\n",
       ")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgc.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CUBLAS_WORKSPACE_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3778094/1329080253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUBLAS_WORKSPACE_CONFIG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py397/lib/python3.9/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CUBLAS_WORKSPACE_CONFIG'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 14:11:26 (INFO): Starting experiment exp_eval_robustness with configuration:\n",
      "2022-08-10 14:11:26 (INFO): data_params: {'graph_model': 'CSBM', 'classes': 2, 'n': 1000, 'n_per_class_trn': 400, 'K': 0.5, 'sigma': 1, 'avg_within_class_degree': 3.0, 'avg_between_class_degree': 1.0, 'inductive_samples': 1000}\n",
      "2022-08-10 14:11:26 (INFO): model_params: {'label': 'GCN', 'model': 'DenseGCN', 'n_filters': 64}\n",
      "2022-08-10 14:11:26 (INFO): train_params: {'lr': 0.01, 'weight_decay': 0.001, 'patience': 300, 'max_epochs': 3000, 'inductive': True}\n",
      "2022-08-10 14:11:26 (INFO): attack_params: {'attack': 'l2'}\n",
      "2022-08-10 14:11:26 (INFO): verbosity_params: {'display_steps': 100, 'debug_lvl': 'info'}\n",
      "2022-08-10 14:11:26 (INFO): other_params: {'device': 0, 'allow_tf32': False, 'sacred_metrics': True}\n",
      "2022-08-10 14:11:26 (INFO): seed: 1\n",
      "2022-08-10 14:11:26 (INFO): db_collection: None\n",
      "2022-08-10 14:11:26 (INFO): Currently on gpu device cuda:0\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch    0: loss_train: 0.70102, loss_val: 0.69805, acc_train: 0.47250, acc_val: 0.49500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  100: loss_train: 0.41914, loss_val: 0.58875, acc_train: 0.80500, acc_val: 0.68500\n",
      "2022-08-10 14:11:27 (INFO): \n",
      "Epoch  200: loss_train: 0.41618, loss_val: 0.60138, acc_train: 0.80000, acc_val: 0.70000\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch  300: loss_train: 0.40287, loss_val: 0.60636, acc_train: 0.81750, acc_val: 0.68500\n",
      "2022-08-10 14:11:28 (INFO): \n",
      "Epoch   66: loss_train: 0.47474, loss_val: 0.58023, acc_train: 0.77750, acc_val: 0.68500\n",
      "2022-08-10 14:11:50 (INFO): Prediction Statistics:\n",
      "2022-08-10 14:11:50 (INFO): Count BC: 861.0 GNN: 694.0\n",
      "2022-08-10 14:11:50 (INFO): Count Structure BC: 855.0 Feature BC: 590.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC and GNN: 640.0\n",
      "2022-08-10 14:11:50 (INFO): Count BC not GNN: 221.0 GNN not BC: 54.0\n",
      "2022-08-10 14:11:50 (INFO): Robustness Statistics:\n",
      "2022-08-10 14:11:50 (INFO): BC more robust than GNN: 175.0\n",
      "2022-08-10 14:11:50 (INFO): BC & GNN equal robustness: 101.0\n",
      "2022-08-10 14:11:50 (INFO): BC less robust than GNN: 364.0\n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <BC robust>: 0.12; <GNN robust>: 1.17; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <BC robust>: 0.65; <GNN robust>: 2.40; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <BC robust>: 1.17; <GNN robust>: 3.83; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <BC robust>: 1.54; <GNN robust>: 2.71; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <BC robust>: 2.01; <GNN robust>: 4.02; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <BC robust>: 2.73; <GNN robust>: 5.47; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <BC robust>: 2.79; <GNN robust>: 5.42; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <BC robust>: 3.24; <GNN robust>: 6.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <BC robust>: 3.94; <GNN robust>: 6.43; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <BC robust>: 3.45; <GNN robust>: 3.22; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <BC robust>: 7.80; <GNN robust>: 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Max(BC robust): 1.00; Max(GNN robust): 6.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Max(BC robust): 2.00; Max(GNN robust): 20.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Max(BC robust): 3.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Max(BC robust): 4.00; Max(GNN robust): 17.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Max(BC robust): 5.00; Max(GNN robust): 16.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Max(BC robust): 6.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Max(BC robust): 6.00; Max(GNN robust): 35.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Max(BC robust): 7.00; Max(GNN robust): 33.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Max(BC robust): 8.00; Max(GNN robust): 21.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Max(BC robust): 7.00; Max(GNN robust): 8.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Max(BC robust): 10.00; Max(GNN robust): 27.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: Median(BC robust): 0.00; Median(GNN robust): 0.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 1: Median(BC robust): 1.00; Median(GNN robust): 1.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 2: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 3: Median(BC robust): 1.00; Median(GNN robust): 2.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 4: Median(BC robust): 2.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 5: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 6: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 7: Median(BC robust): 3.00; Median(GNN robust): 4.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 8: Median(BC robust): 4.00; Median(GNN robust): 5.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 9: Median(BC robust): 3.00; Median(GNN robust): 3.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 10: Median(BC robust): 8.00; Median(GNN robust): 12.00; \n",
      "2022-08-10 14:11:50 (INFO): Degree 0: <GNN wrt BC robust>: 0.17/0.17. <GNN in wrt BC setting>: 1.17\n",
      "2022-08-10 14:11:50 (INFO): Degree 1: <GNN wrt BC robust>: 0.54/0.74. <GNN in wrt BC setting>: 2.64\n",
      "2022-08-10 14:11:50 (INFO): Degree 2: <GNN wrt BC robust>: 0.99/1.25. <GNN in wrt BC setting>: 4.11\n",
      "2022-08-10 14:11:50 (INFO): Degree 3: <GNN wrt BC robust>: 1.12/1.71. <GNN in wrt BC setting>: 2.81\n",
      "2022-08-10 14:11:50 (INFO): Degree 4: <GNN wrt BC robust>: 1.65/2.08. <GNN in wrt BC setting>: 4.12\n",
      "2022-08-10 14:11:50 (INFO): Degree 5: <GNN wrt BC robust>: 2.28/2.98. <GNN in wrt BC setting>: 5.54\n",
      "2022-08-10 14:11:50 (INFO): Degree 6: <GNN wrt BC robust>: 2.46/2.93. <GNN in wrt BC setting>: 5.66\n",
      "2022-08-10 14:11:50 (INFO): Degree 7: <GNN wrt BC robust>: 2.73/3.70. <GNN in wrt BC setting>: 6.27\n",
      "2022-08-10 14:11:50 (INFO): Degree 8: <GNN wrt BC robust>: 3.41/4.19. <GNN in wrt BC setting>: 6.67\n",
      "2022-08-10 14:11:50 (INFO): Degree 9: <GNN wrt BC robust>: 2.11/3.44. <GNN in wrt BC setting>: 3.22\n",
      "2022-08-10 14:11:50 (INFO): Degree 10: <GNN wrt BC robust>: 6.00/7.80. <GNN in wrt BC setting>: 12.00\n"
     ]
    }
   ],
   "source": [
    "data_params[\"sigma\"] = 1\n",
    "seed = 1\n",
    "\n",
    "result = exp_eval_robustness.run(data_params, model_params, train_params, attack_params, verbosity_params, other_params, seed, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import calc_balanced_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 25 25]\n"
     ]
    }
   ],
   "source": [
    "class_counts = [10, 100, 100]\n",
    "n_samples = 60\n",
    "print(calc_balanced_sample(class_counts, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.Tensor([[0.8, 0.2], [0.1, 0.9]])\n",
    "labels = torch.Tensor([0, 1])\n",
    "logits.argmax(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

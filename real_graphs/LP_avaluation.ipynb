{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1394a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from rgnn_at_scale.models import GCN\n",
    "from src.models.lp import LP\n",
    "from rgnn_at_scale.attacks import FGSM\n",
    "from tqdm import tqdm\n",
    "from torch_sparse import SparseTensor\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from rgnn_at_scale.data import prep_graph, split\n",
    "from src.helpers import delete_idx_from_data\n",
    "from rgnn_at_scale.helper.io import Storage\n",
    "device=0\n",
    "\n",
    "from rgnn_at_scale.helper.utils import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cdecc",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cffea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dataset='cora_ml', seed = 0, label='GCN', n_classes = 7, device = 0):\n",
    "    if label == 'LP':\n",
    "        model = Dummy_model(n_classes, device)\n",
    "    else:\n",
    "        store = Storage(cache_dir = '../cache')\n",
    "        model_params = {\"dataset\": dataset, \"binary_attr\": False, \"make_undirected\": True, \"seed\": seed, \"label\": label}\n",
    "        models_and_hyperparams = store.find_models('overrobust_final', model_params)\n",
    "        model = models_and_hyperparams[0][0].to(device)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ccfcc",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69df726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset, device=0, seed = 0):\n",
    "    graph = prep_graph(dataset, device, dataset_root='datasets', make_undirected=True,\n",
    "                           binary_attr=False, return_original_split=dataset.startswith('ogbn'))\n",
    "\n",
    "    attr, adj, labels = graph[:3]\n",
    "    if len(graph) == 3 or graph[3] is None:  # TODO: This is weird\n",
    "        idx_test, idx_val, idx_train = split(labels.cpu().numpy(), n_per_class=40)\n",
    "    else:\n",
    "        idx_train, idx_val, idx_test = graph[3]['train'], graph[3]['valid'], graph[3]['test']\n",
    "        \n",
    "        #idx_keep = []\n",
    "        #n_per_class=65\n",
    "        #for c in labels.unique():\n",
    "        #    idx = (labels[idx_test_orig] == c).nonzero().flatten()\n",
    "        #    stop = min(len(idx), n_per_class)\n",
    "        #    idx_keep.append(idx[torch.randperm(len(idx))[:stop]])\n",
    "        #idx_test = torch.cat(idx_keep).cpu().numpy()\n",
    "        \n",
    "    _, adj_train = delete_idx_from_data(attr, adj, np.concatenate([idx_test, idx_val]))\n",
    "    _, adj_val = delete_idx_from_data(attr, adj, idx_test)\n",
    "    return attr, adj_val, adj, idx_train, idx_val, idx_test, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da29715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr, adj_val, adj, idx_train, idx_val, idx_test, labels =  load_dataset('ogbn-arxiv') \n",
    "idx_keep = []\n",
    "test_map = torch.zeros_like(labels)\n",
    "test_map[idx_test]=1\n",
    "for c in labels.unique():\n",
    "    idx = ((labels == c) & test_map).nonzero().flatten()\n",
    "    stop = min(len(idx), 40)\n",
    "    idx_keep.append(idx[torch.randperm(len(idx))[:stop]])\n",
    "idx_new = torch.cat(idx_keep).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba556689",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbe6d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, tensor(2., device='cuda:0'))\n",
      "(1, tensor(6., device='cuda:0'))\n",
      "(2, tensor(23., device='cuda:0'))\n",
      "(3, tensor(21., device='cuda:0'))\n",
      "(4, tensor(58., device='cuda:0'))\n",
      "(5, tensor(39., device='cuda:0'))\n",
      "(6, tensor(20., device='cuda:0'))\n",
      "(7, tensor(5., device='cuda:0'))\n",
      "(8, tensor(39., device='cuda:0'))\n",
      "(9, tensor(11., device='cuda:0'))\n",
      "(10, tensor(45., device='cuda:0'))\n",
      "(11, tensor(8., device='cuda:0'))\n",
      "(12, tensor(1., device='cuda:0'))\n",
      "(13, tensor(20., device='cuda:0'))\n",
      "(14, tensor(3., device='cuda:0'))\n",
      "(15, tensor(3., device='cuda:0'))\n",
      "(16, tensor(324., device='cuda:0'))\n",
      "(17, tensor(7., device='cuda:0'))\n",
      "(18, tensor(7., device='cuda:0'))\n",
      "(19, tensor(13., device='cuda:0'))\n",
      "(20, tensor(10., device='cuda:0'))\n",
      "(21, tensor(2., device='cuda:0'))\n",
      "(22, tensor(12., device='cuda:0'))\n",
      "(23, tensor(25., device='cuda:0'))\n",
      "(24, tensor(332., device='cuda:0'))\n",
      "(25, tensor(15., device='cuda:0'))\n",
      "(26, tensor(33., device='cuda:0'))\n",
      "(27, tensor(64., device='cuda:0'))\n",
      "(28, tensor(88., device='cuda:0'))\n",
      "(29, tensor(4., device='cuda:0'))\n",
      "(30, tensor(143., device='cuda:0'))\n",
      "(31, tensor(28., device='cuda:0'))\n",
      "(32, tensor(3., device='cuda:0'))\n",
      "(33, tensor(7., device='cuda:0'))\n",
      "(34, tensor(44., device='cuda:0'))\n",
      "(35, tensor(2., device='cuda:0'))\n",
      "(36, tensor(20., device='cuda:0'))\n",
      "(37, tensor(15., device='cuda:0'))\n",
      "(38, tensor(7., device='cuda:0'))\n",
      "(39, tensor(9., device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "attr, adj_val, adj, idx_train, idx_val, idx_test, labels =  load_dataset('ogbn-arxiv') \n",
    "# compute n_per_class\n",
    "n_total = 1500\n",
    "bins = labels[idx_test].bincount()\n",
    "bins_ratio = bins/bins.sum()\n",
    "n_per_class = (n_total*bins_ratio).ceil()\n",
    "# subsample test set\n",
    "idx_keep = []\n",
    "test_map = torch.zeros_like(labels)\n",
    "test_map[idx_test]=1\n",
    "for c,n in enumerate(n_per_class):\n",
    "    print((c, n))\n",
    "    idx = ((labels == c) & test_map).nonzero().flatten()\n",
    "    idx_keep.append(idx[torch.randperm(len(idx))[:int(n)]])\n",
    "idx_new = torch.cat(idx_keep).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94f2eab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.,   6.,  23.,  21.,  58.,  39.,  20.,   5.,  39.,  11.,  45.,   8.,\n",
       "          1.,  20.,   3.,   3., 324.,   7.,   7.,  13.,  10.,   2.,  12.,  25.,\n",
       "        332.,  15.,  33.,  64.,  88.,   4., 143.,  28.,   3.,   7.,  44.,   2.,\n",
       "         20.,  15.,   7.,   9.], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2edbc7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   54,   187,   733,   654,  1869,  1246,   622,   134,  1250,   345,\n",
       "         1455,   239,     5,   628,    71,    87, 10477,   203,   209,   419,\n",
       "          313,    51,   386,   808, 10740,   475,  1041,  2066,  2849,   120,\n",
       "         4631,   892,    83,   220,  1414,    36,   627,   481,   214,   269],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[idx_test].bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1f86002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  437,   382,  3604,  1014,  2864,  2933,   703,   380,  4056,  2245,\n",
       "         5182,   391,    21,  1290,   473,   248,  9998,   202,   402,  1873,\n",
       "         1495,   304,  1268,  1539,  6989,   457,  2854,  1661, 16284,   239,\n",
       "         4334,  1350,   270,   926,  5426,    75,  2506,  1615,  1100,  1551],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[idx_train].bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70fefce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48603,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a59b6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (labels[idx_test] == 0).nonzero().flatten()\n",
    "stop = min(len(idx), 40)\n",
    "idx_keep.append(idx[torch.randperm(len(idx))[:stop]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "464e39d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2869702e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,   6,  23,  21,  58,  39,  20,   5,  39,  11,  45,   8,   1,  20,\n",
       "          3,   3, 324,   7,   7,  13,  10,   2,  12,  25, 332,  15,  33,  64,\n",
       "         88,   4, 143,  28,   3,   7,  44,   2,  20,  15,   7,   9],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x in idx_test for x in idx_new]\n",
    "labels[idx_new].bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c74f4492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_new[0] in idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dff5075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1561"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f5a1e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   346,    398,    451, ..., 169340, 169341, 169342])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69c908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70db4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dummy_model():\n",
    "    def __init__(self, n_classes, device = 0):\n",
    "        self.out_dim = n_classes\n",
    "        self.device = device\n",
    "\n",
    "    def eval(self):\n",
    "        pass\n",
    "\n",
    "    def train(self): \n",
    "        pass\n",
    "\n",
    "    def __call__(self, attr, adj):\n",
    "        return torch.zeros(attr.shape[0], self.out_dim).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae364be",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'LP'\n",
    "seed = 0\n",
    "device = 0\n",
    "dataset = 'cora_ml'\n",
    "n_classes = 7\n",
    "lp_params = {'num_layers': 1, 'alpha': 0.1, 'num_classes': 7}\n",
    "\n",
    "\n",
    "def evaluate_lp(label, lp_params, dataset, device=0, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # load dataset\n",
    "    attr, adj_val, adj_test, idx_train, idx_val, idx_test, labels = load_dataset(dataset, device, seed)\n",
    "\n",
    "    # load model \n",
    "    model = load_model(dataset, seed, label, lp_params['num_classes'], device)\n",
    "\n",
    "    # construct LP\n",
    "    lp = LP(**lp_params)\n",
    "    mask = torch.zeros_like(labels)\n",
    "    mask[idx_train]=1\n",
    "    lp_input = {'y_true': labels[idx_train], 'mask': mask.bool()}\n",
    "\n",
    "    # evaluate val acc + loss\n",
    "    model.eval()\n",
    "    logits = model(attr, adj_val)\n",
    "    logits = lp.smooth(y_soft=logits, A = adj_val, **lp_input)\n",
    "    acc_val = accuracy(logits, labels, idx_val)\n",
    "    loss_val = F.cross_entropy(logits[idx_val], labels[idx_val])\n",
    "\n",
    "    # evaluate test acc + loss\n",
    "    model.eval()\n",
    "    logits = model(attr, adj_test)\n",
    "    logits = lp.smooth(y_soft=logits, A = adj_test, **lp_input)\n",
    "    acc_test = accuracy(logits, labels, idx_test)\n",
    "    loss_test = F.cross_entropy(logits[idx_test], labels[idx_test])\n",
    "\n",
    "    return acc_test, loss_test.item(), acc_val, loss_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b4ae24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:10,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "grid = {'label': ['LP'],\n",
    "        'seed': [0,1,5,6,7,8,9,10],\n",
    "        'num_layers': [10],\n",
    "        'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "        'num_classes': [7],\n",
    "        'dataset': ['cora_ml']}\n",
    "\n",
    "grid_list = (dict(zip(grid, vs)) for vs in product(*grid.values()))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for x in tqdm(grid_list):\n",
    "    y = x.copy()\n",
    "    x['lp_params'] = {'num_layers':x['num_layers'],\n",
    "                     'alpha': x['alpha'],\n",
    "                     'num_classes': x['num_classes']}\n",
    "    x.pop('num_layers')\n",
    "    x.pop('alpha')\n",
    "    x.pop('num_classes')\n",
    "    \n",
    "    acc_test, loss_test, acc_val, loss_val = evaluate_lp(**x, device=0)\n",
    "    y['acc_test'] = acc_test\n",
    "    y['acc_val'] = acc_val\n",
    "    y['loss_test'] = loss_test\n",
    "    y['loss_val'] = loss_val\n",
    "    df = df.append(y, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "861444c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:07,  9.82it/s]\n"
     ]
    }
   ],
   "source": [
    "grid = {'label': ['LP'],\n",
    "        'seed': [0,1,5,6,7,8,9,10],\n",
    "        'num_layers': [10],\n",
    "        'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "        'num_classes': [6],\n",
    "        'dataset': ['citeseer']}\n",
    "\n",
    "grid_list = (dict(zip(grid, vs)) for vs in product(*grid.values()))\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "for x in tqdm(grid_list):\n",
    "    y = x.copy()\n",
    "    x['lp_params'] = {'num_layers':x['num_layers'],\n",
    "                     'alpha': x['alpha'],\n",
    "                     'num_classes': x['num_classes']}\n",
    "    x.pop('num_layers')\n",
    "    x.pop('alpha')\n",
    "    x.pop('num_classes')\n",
    "    \n",
    "    acc_test, loss_test, acc_val, loss_val = evaluate_lp(**x, device=0)\n",
    "    y['acc_test'] = acc_test\n",
    "    y['acc_val'] = acc_val\n",
    "    y['loss_test'] = loss_test\n",
    "    y['loss_val'] = loss_val\n",
    "    df = df.append(y, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0823877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "grid = {'label': ['GCN', 'LP'],\n",
    "        'seed': [0,1,5,6,7],\n",
    "        'num_layers': [10],\n",
    "        'alpha': [0.1, 0.2, 0.5, 0.8], \n",
    "        'num_classes': [40],\n",
    "        'dataset': ['ogbn-arxiv']}\n",
    "\n",
    "grid = {'label': ['LP'],\n",
    "        'seed': [0],\n",
    "        'num_layers': [10],\n",
    "        'alpha': [0.7], \n",
    "        'num_classes': [40],\n",
    "        'dataset': ['ogbn-arxiv']}\n",
    "\n",
    "grid_list = (dict(zip(grid, vs)) for vs in product(*grid.values()))\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "for x in tqdm(grid_list):\n",
    "    y = x.copy()\n",
    "    x['lp_params'] = {'num_layers':x['num_layers'],\n",
    "                     'alpha': x['alpha'],\n",
    "                     'num_classes': x['num_classes']}\n",
    "    x.pop('num_layers')\n",
    "    x.pop('alpha')\n",
    "    x.pop('num_classes')\n",
    "    \n",
    "    acc_test, loss_test, acc_val, loss_val = evaluate_lp(**x, device=0)\n",
    "    y['acc_test'] = acc_test\n",
    "    y['acc_val'] = acc_val\n",
    "    y['loss_test'] = loss_test\n",
    "    y['loss_val'] = loss_val\n",
    "    df = df.append(y, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f7899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_val</th>\n",
       "      <th>alpha</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "      <th>loss_test</th>\n",
       "      <th>loss_val</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.832143</td>\n",
       "      <td>0.1</td>\n",
       "      <td>cora_ml</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.906893</td>\n",
       "      <td>1.903485</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>cora_ml</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.870653</td>\n",
       "      <td>1.864697</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.3</td>\n",
       "      <td>cora_ml</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.837052</td>\n",
       "      <td>1.829328</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.4</td>\n",
       "      <td>cora_ml</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.806125</td>\n",
       "      <td>1.797348</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.832143</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cora_ml</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.778151</td>\n",
       "      <td>1.768980</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.6</td>\n",
       "      <td>citeseer</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.631629</td>\n",
       "      <td>1.618761</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.7</td>\n",
       "      <td>citeseer</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.613935</td>\n",
       "      <td>1.599007</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.8</td>\n",
       "      <td>citeseer</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.600053</td>\n",
       "      <td>1.584177</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>citeseer</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.594280</td>\n",
       "      <td>1.580078</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.677407</td>\n",
       "      <td>0.670526</td>\n",
       "      <td>0.7</td>\n",
       "      <td>ogbn-arxiv</td>\n",
       "      <td>LP</td>\n",
       "      <td>3.600137</td>\n",
       "      <td>3.557057</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acc_test   acc_val  alpha     dataset label  loss_test  loss_val  \\\n",
       "0    0.850000  0.832143    0.1     cora_ml    LP   1.906893  1.903485   \n",
       "1    0.850000  0.835714    0.2     cora_ml    LP   1.870653  1.864697   \n",
       "2    0.853571  0.835714    0.3     cora_ml    LP   1.837052  1.829328   \n",
       "3    0.864286  0.839286    0.4     cora_ml    LP   1.806125  1.797348   \n",
       "4    0.864286  0.832143    0.5     cora_ml    LP   1.778151  1.768980   \n",
       "..        ...       ...    ...         ...   ...        ...       ...   \n",
       "140  0.675000  0.695833    0.6    citeseer    LP   1.631629  1.618761   \n",
       "141  0.662500  0.691667    0.7    citeseer    LP   1.613935  1.599007   \n",
       "142  0.650000  0.695833    0.8    citeseer    LP   1.600053  1.584177   \n",
       "143  0.645833  0.683333    0.9    citeseer    LP   1.594280  1.580078   \n",
       "144  0.677407  0.670526    0.7  ogbn-arxiv    LP   3.600137  3.557057   \n",
       "\n",
       "     num_classes  num_layers  seed  \n",
       "0            7.0        10.0   0.0  \n",
       "1            7.0        10.0   0.0  \n",
       "2            7.0        10.0   0.0  \n",
       "3            7.0        10.0   0.0  \n",
       "4            7.0        10.0   0.0  \n",
       "..           ...         ...   ...  \n",
       "140          6.0        10.0  10.0  \n",
       "141          6.0        10.0  10.0  \n",
       "142          6.0        10.0  10.0  \n",
       "143          6.0        10.0  10.0  \n",
       "144         40.0        10.0   0.0  \n",
       "\n",
       "[145 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fbbd715",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers</th>\n",
       "      <th>alpha</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">10.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.903997</td>\n",
       "      <td>0.806696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.865742</td>\n",
       "      <td>0.808482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.830869</td>\n",
       "      <td>0.809821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.799303</td>\n",
       "      <td>0.812946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.771318</td>\n",
       "      <td>0.813393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.747497</td>\n",
       "      <td>0.817857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.729336</td>\n",
       "      <td>0.817411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.720197</td>\n",
       "      <td>0.814732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.726946</td>\n",
       "      <td>0.807589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        loss_val   acc_val\n",
       "num_layers alpha label                    \n",
       "10.0       0.1   LP     1.903997  0.806696\n",
       "           0.2   LP     1.865742  0.808482\n",
       "           0.3   LP     1.830869  0.809821\n",
       "           0.4   LP     1.799303  0.812946\n",
       "           0.5   LP     1.771318  0.813393\n",
       "           0.6   LP     1.747497  0.817857\n",
       "           0.7   LP     1.729336  0.817411\n",
       "           0.8   LP     1.720197  0.814732\n",
       "           0.9   LP     1.726946  0.807589"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df.groupby(['dataset', 'num_layers', 'alpha', 'label']).mean()\n",
    "df[df['dataset']=='cora_ml'].groupby(['num_layers', 'alpha', 'label']).mean()[['loss_val', 'acc_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed602018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers</th>\n",
       "      <th>alpha</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">10.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.757943</td>\n",
       "      <td>0.661979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.727363</td>\n",
       "      <td>0.664583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.699559</td>\n",
       "      <td>0.665625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.674080</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.650692</td>\n",
       "      <td>0.668229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.629468</td>\n",
       "      <td>0.670833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.610809</td>\n",
       "      <td>0.672396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.596252</td>\n",
       "      <td>0.670313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <th>LP</th>\n",
       "      <td>1.590087</td>\n",
       "      <td>0.664583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        loss_val   acc_val\n",
       "num_layers alpha label                    \n",
       "10.0       0.1   LP     1.757943  0.661979\n",
       "           0.2   LP     1.727363  0.664583\n",
       "           0.3   LP     1.699559  0.665625\n",
       "           0.4   LP     1.674080  0.668229\n",
       "           0.5   LP     1.650692  0.668229\n",
       "           0.6   LP     1.629468  0.670833\n",
       "           0.7   LP     1.610809  0.672396\n",
       "           0.8   LP     1.596252  0.670313\n",
       "           0.9   LP     1.590087  0.664583"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['dataset']=='citeseer'].groupby(['num_layers', 'alpha', 'label']).mean()[['loss_val', 'acc_val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da18b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss_val</th>\n",
       "      <th>acc_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_layers</th>\n",
       "      <th>alpha</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <th>0.7</th>\n",
       "      <th>LP</th>\n",
       "      <td>3.557057</td>\n",
       "      <td>0.670526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        loss_val   acc_val\n",
       "num_layers alpha label                    \n",
       "10.0       0.7   LP     3.557057  0.670526"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['dataset']=='ogbn-arxiv'].groupby(['num_layers', 'alpha', 'label']).mean()[['loss_val', 'acc_val']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13eef4",
   "metadata": {},
   "source": [
    "# dataset statistics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf2612a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def histplot_degree_distr(A, title=\"CORA\", max_plot_deg=None):\n",
    "    deg = np.sum(A, axis=1)\n",
    "    max_deg = np.max(deg)\n",
    "    print(f\"Average Degree: {np.sum(deg) / deg.shape[0]:.2f}\")\n",
    "    print(f\"Maximum Degree: {max_deg}\")\n",
    "    c = Counter(deg)\n",
    "    ordered_c = [c[i] if i in c else 0 for i in range(max_deg+1)]\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    #print(ordered_c)\n",
    "    bins = [i for i in range(len(ordered_c)+1)] \n",
    "    #axs.hist(bins[:-1], bins, weights=ordered_c, color=\"blue\", rwidth=0.7, alpha=0.5)\n",
    "    axs.bar(bins[:-1], ordered_c, alpha=0.8)\n",
    "    #counts, bins = np.histogram(deg)\n",
    "    #axs.stairs(bins, counts)\n",
    "    if max_plot_deg is not None:\n",
    "        axs.set_xlim(left=0, right=max_plot_deg)\n",
    "    axs.set_ylabel(\"Number of Nodes\")\n",
    "    axs.set_xlabel(\"Node Degree\")\n",
    "    axs.set_title(title)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3574cc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([115, 463, 388, 304, 532, 308], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'citeseer'\n",
    "attr, adj_val, adj, idx_train, idx_val, idx_test, labels = load_dataset(dataset, device=0, seed = 0)\n",
    "labels.bincount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "32fecc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(dataset):\n",
    "    attr, adj_val, adj, idx_train, idx_val, idx_test, labels = load_dataset(dataset, device=0, seed = 0)\n",
    "    #Nodes,\n",
    "    n_nodes = attr.shape[0]\n",
    "    #Edges, \n",
    "    n_edges = adj.sum()/2\n",
    "    #Features,\n",
    "    n_features = attr.shape[1]\n",
    "    #Classes, \n",
    "    n_classes = len(labels.unique())\n",
    "    #Average Node Degree, \n",
    "    avg_node_degree = adj.sum(dim=0).mean()\n",
    "    #Average Same-Class Node Degree, \n",
    "    mask = labels.repeat(n_nodes, 1) == labels.repeat(n_nodes, 1).T\n",
    "    avg_node_degree_same = (mask*adj.to_dense()).sum(dim=0).mean()\n",
    "    #Average Different-Class Node Degree\n",
    "    mask = labels.repeat(n_nodes, 1) != labels.repeat(n_nodes, 1).T\n",
    "    avg_node_degree_other = (mask*adj.to_dense()).sum(dim=0).mean()\n",
    "    return {'# Nodes': n_nodes,\n",
    "            '# Edges': int(n_edges.cpu().numpy()),\n",
    "            '# Features': n_features,\n",
    "            '# Classes': n_classes,\n",
    "            'Average Node Degree': float(avg_node_degree.cpu().numpy()),\n",
    "            'Average Same-Class Node Degree': float(avg_node_degree_same.cpu().numpy()),\n",
    "            'Average Different-Class Node Degree': float(avg_node_degree_other.cpu().numpy())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89020239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "{} &  \\# Nodes &  \\# Edges &  \\# Features &  \\# Classes &  Average Node Degree &  Average Same-Class Node Degree &  Average Different-Class Node Degree \\\\\n",
      "Dataset  &          &          &             &            &                      &                                 &                                      \\\\\n",
      "\\midrule\n",
      "Cora-ML  &     2810 &     7981 &        2879 &          7 &                 5.68 &                            4.46 &                                 1.22 \\\\\n",
      "Citeseer &     2110 &     3668 &        3703 &          6 &                 3.48 &                            2.56 &                                 0.92 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "datasets = [('cora_ml', 'Cora-ML'), ('citeseer', 'Citeseer')]\n",
    "for dataset, title in datasets:\n",
    "    data_dict = get_statistics(dataset)\n",
    "    data_dict['Dataset'] = title\n",
    "    df = df.append(data_dict, ignore_index=True)\n",
    "cols = ['# Nodes','# Edges','# Features','# Classes','Average Node Degree','Average Same-Class Node Degree','Average Different-Class Node Degree']\n",
    "df = df.round(decimals=2)\n",
    "df[['# Nodes','# Edges','# Features','# Classes']] = df[['# Nodes','# Edges','# Features','# Classes']].astype(int)\n",
    "df = df.set_index('Dataset')\n",
    "print(df[cols].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f1eabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Degree: 3.48\n",
      "Maximum Degree: 99\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = histplot_degree_distr(adj.to_dense().cpu().int().numpy(), title='Citeseer', max_plot_deg=15)\n",
    "fig.savefig('../results/images_overrobust/citeseer/degree_plot.pdf', bbox_inches='tight', format='pdf') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9806fd15aa752b4615abd2f6adec40f9b26b8922651ea05880f7f6f75c02fe55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules automatically\n",
    "# https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from strn_and_rbstness.data import GraphDataset, split\n",
    "from strn_and_rbstness.helper.utils import accuracy\n",
    "from strn_and_rbstness.models import create_model\n",
    "from strn_and_rbstness.train import _train\n",
    "from common import CSBM, get_sbm_model, add_adversarial_edge\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "avg_intra_degree = 1.5 * 2 # intra_edges_per_node * 2\n",
    "avg_inter_degree = 0.5 * 2\n",
    "csbm = get_sbm_model(n, avg_intra_degree, avg_inter_degree)\n",
    "seed = 1\n",
    "X, A, y = csbm.sample(n, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Currently on gpu device cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_params = dict(\n",
    "    label=\"GCN\",\n",
    "    model=\"DenseGCN\", #GCN or DenseGCN\n",
    "    n_filters=64,\n",
    "    dropout=0.5\n",
    ")\n",
    "train_params = dict(\n",
    "    loss_type=\"CE\",\n",
    "    lr=1e-2,\n",
    "    weight_decay=1e-3,\n",
    "    patience=300,\n",
    "    max_epochs=1000,\n",
    "    use_selftrain = False, \n",
    "    use_advtrain = False,\n",
    ")\n",
    "attack = \"LocalDICEUndirected\"\n",
    "attack_params = dict()\n",
    "\n",
    "# Other\n",
    "split_params = {\n",
    "    \"strategy\": \"normal\", # or \"custom\"\n",
    "    \"p_trn\": 1,\n",
    "    \"p_tst\": 0, # \"normal\" uses 1 - p_trn, only for custom split strategy\n",
    "    \"p_selftrn\": 0 # Refers to unlabeled data, which is not test data, \n",
    "                    # only for custom split strategy\n",
    "}\n",
    "verbosity_params = dict(\n",
    "    display_steps = 1001\n",
    ")   \n",
    "# Device\n",
    "device = 0\n",
    "if not torch.cuda.is_available():\n",
    "    device == \"cpu\", \"CUDA is not availble, set device to 'cpu'\"\n",
    "else:\n",
    "    device = torch.device(f\"cuda:{device}\")\n",
    "    logging.info(f\"Currently on gpu device {device}\")\n",
    "attack_params[\"data_device\"] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "Epoch    0: loss_train: 0.69339, loss_val: 0.69347, acc_train: 0.48800, acc_val: 0.49000\n",
      "INFO:root:\n",
      "Epoch  250: loss_train: 0.49040, loss_val: 0.59152, acc_train: 0.76800, acc_val: 0.69400\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "split_ids = split(y, split_params, seed)\n",
    "X_gpu = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "A_gpu = torch.tensor(A, dtype=torch.float32, device=device)\n",
    "y_gpu = torch.tensor(y, device=device)\n",
    "graph = GraphDataset((X_gpu, A_gpu, y_gpu), split_ids)\n",
    "model_params_trn = dict(**model_params, \n",
    "                        n_features=graph.get_n_features(), \n",
    "                        n_classes=graph.get_n_classes())\n",
    "model = create_model(model_params_trn).to(device)\n",
    "statistics = _train(model, graph, train_params, verbosity_params, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 1]\n",
      "[  2   3   9  10  12  15  16  18  19  20  22  23  25  26  27  29  30  31\n",
      "  37  38  39  46  49  50  52  53  57  59  60  63  68  69  72  73  74  75\n",
      "  79  81  82  85  88  90  91  95  98 103 104 105 106 107 115 116 117 118\n",
      " 119 120 127 128 131 132 134 135 136 142 144 146 147 148 152 154 155 156\n",
      " 157 159 161 165 166 167 168 169 170 172 173 175 176 179 180 181 183 184\n",
      " 185 186 188 189 190 191 194 195 199 200 201 202 203 207 210 211 212 215\n",
      " 219 224 226 227 229 231 234 237 241 243 245 252 253 256 257 258 261 262\n",
      " 263 264 265 273 274 276 277 278 280 282 284 285 286 287 290 291 292 294\n",
      " 297 298 300 302 303 304 306 308 312 314 319 320 322 323 324 325 328 331\n",
      " 332 340 341 342 343 344 345 346 348 349 350 351 352 357 358 359 361 363\n",
      " 365 366 367 368 369 370 372 373 374 376 379 380 383 385 387 390 391 393\n",
      " 394 395 396 397 400 401 406 408 410 411 413 415 417 418 419 420 422 423\n",
      " 429 430 431 433 436 439 440 443 448 450 451 452 453 454 456 457 458 459\n",
      " 461 462 464 467 469 471 473 474 475 476 478 484 486 488 489 490 491 494\n",
      " 495 496 497 499 500 505 508 510 511 513 514 515 520 521 522 523 525 528\n",
      " 529 532 535 536 537 538 540 541 542 543 545 547 548 552 553 555 556 557\n",
      " 558 559 565 566 569 570 571 572 574 575 576 578 580 581 582 583 585 586\n",
      " 589 595 596 597 598 599 600 601 602 604 605 606 608 610 612 613 620 621\n",
      " 622 624 625 627 630 631 632 635 638 639 640 641 643 644 646 647 648 649\n",
      " 650 651 654 655 656 657 658 659 662 664 665 667 671 672 673 679 681 683\n",
      " 684 685 686 687 688 689 690 691 692 694 696 697 700 701 705 708 713 715\n",
      " 720 724 725 727 730 731 733 734 735 736 737 738 742 743 745 747 748 752\n",
      " 754 755 756 761 763 765 766 767 768 770 771 772 777 778 779 781 782 783\n",
      " 786 787 788 791 798 801 802 809 810 811 812 819 820 824 825 828 829 830\n",
      " 831 834 835 836 837 839 842 843 844 845 846 848 849 851 852 853 855 857\n",
      " 858 859 864 865 866 868 870 873 875 877 878 881 883 884 886 887 889 891\n",
      " 893 901 902 905 906 909 913 914 915 917 921 923 924 925 928 930 931 933\n",
      " 934 935 937 938 940 944 946 947 948 950 953 954 956 959 960 962 963 972\n",
      " 975 979 980 981 982 983 984 985 987 989 990 993 994 995 996 997 998 999]\n",
      "Count BC: 1; GNN: 0\n",
      "Count Structure BC: 1; Feature BC: 0\n",
      "Count BC and GNN: 0 \n",
      "Count BC not GNN: 1; GNN not BC: 0\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1\n",
    "model.eval()\n",
    "c_acc_bayes = 0 # Count nodes correctly classified by bayes classifier\n",
    "c_acc_bayes_deg = Counter()  # Above but for each degree\n",
    "c_acc_bayes_structure = 0 # Count nodes separable by structure alone\n",
    "c_acc_bayes_structure_deg = Counter() # Above but for each degree\n",
    "c_acc_bayes_feature = 0 # Count nodes separable by features alone (degree dependent\n",
    "                        # doesn't make sense as features independent of connections)\n",
    "c_acc_bayes_not_gnn = 0 # Decisions where BC correct but GNN wrong\n",
    "c_acc_bayes_not_gnn_deg = Counter() # Above but for each degree\n",
    "c_acc_gnn = 0 # Count nodes correctly classified by gnn\n",
    "c_acc_gnn_deg = Counter() # Above but for each degree\n",
    "c_acc_gnn_not_bayes = 0 # Decisions where GNN correctly says true even though BC violated\n",
    "c_acc_gnn_not_bayes_deg = Counter() # Above but for each degree\n",
    "c_acc_bayes_gnn = 0 # Count nodes correctly classified by bc & gnn\n",
    "c_acc_bayes_gnn_deg = Counter() # Above but for each degree\n",
    "c_degree_total = Counter() # Count degrees of all generated nodes\n",
    "c_degree_acc_bayes = Counter() # Count degrees where bayes classifier is correct\n",
    "c_degree_acc_gnn = Counter() # Count degrees where gnn is correct\n",
    "c_degree_acc_bayes_gnn = Counter() # Count degrees where bc & gnn are correct\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "for i in range(n_iter):\n",
    "    # ToDo: Create empty X_, A_, y_ templates & always only fill last row\n",
    "    X_, A_, y_ = csbm.sample_conditional(n=1, X=X, A=A, y=y)\n",
    "    deg_n = np.sum(A_[:,n])\n",
    "    c_degree_total[deg_n] += 1\n",
    "    # Statistics Bayes Classifier\n",
    "    feature_separable, _ = csbm.feature_separability(X_, y_, [n])\n",
    "    structure_separable, _ = csbm.structure_separability(A_, y_, [n])\n",
    "    bayes_separable, _ = csbm.likelihood_separability(X_, A_, y_, [n])\n",
    "    if bayes_separable:\n",
    "        c_acc_bayes += 1\n",
    "        c_acc_bayes_deg[deg_n] += 1\n",
    "    if structure_separable:\n",
    "        c_acc_bayes_structure += 1\n",
    "        c_acc_bayes_structure_deg[deg_n] += 1\n",
    "    if feature_separable:\n",
    "        c_acc_bayes_feature += 1\n",
    "    # Calculate GNN-prediction\n",
    "    X_gpu = torch.tensor(X_, dtype=torch.float32, device=device)\n",
    "    A_gpu = torch.tensor(A_, dtype=torch.float32, device=device)\n",
    "    y_gpu = torch.tensor(y_, device=device)\n",
    "    logits = model(X_gpu, A_gpu)\n",
    "    gnn_separable = round(accuracy(logits, y_gpu, n))\n",
    "    # Statistics Prediction\n",
    "    if gnn_separable:\n",
    "        c_acc_gnn += 1\n",
    "        c_acc_gnn_deg[deg_n] += 1\n",
    "        if bayes_separable:\n",
    "            c_acc_bayes_gnn += 1\n",
    "            c_acc_bayes_gnn_deg[deg_n] += 1\n",
    "        else:\n",
    "            c_acc_gnn_not_bayes += 1\n",
    "            c_acc_gnn_not_bayes_deg[deg_n] += 1\n",
    "    elif bayes_separable:\n",
    "        c_acc_bayes_not_gnn += 1\n",
    "        c_acc_bayes_not_gnn_deg[deg_n] += 1\n",
    "    # Investigate Robustness\n",
    "    c_robustness = 0\n",
    "    while bayes_separable or gnn_separable:\n",
    "        j = add_adversarial_edge(n, A_, y_) #ToDo: For speed, calc pot_neighbours once!\n",
    "        A_gpu[n, j] = 1\n",
    "        A_gpu[j, n] = 1\n",
    "\n",
    "        if bayes_separable:\n",
    "            bayes_separable_new, _ = csbm.likelihood_separability(X_, A_, y_, [n])\n",
    "            if not bayes_separable_new:\n",
    "                \n",
    "\n",
    "        break\n",
    "        # Case: Bayes & GNN-Separable\n",
    "        # Case: Bayes & not-GNN-separable\n",
    "        # Case: GNN & not Bayes-separable\n",
    "\n",
    "print(f\"Count BC: {c_acc_bayes}; GNN: {c_acc_gnn}\")\n",
    "print(f\"Count Structure BC: {c_acc_bayes_structure}; Feature BC: {c_acc_bayes_feature}\")\n",
    "print(f\"Count BC and GNN: {c_acc_bayes_gnn} \")\n",
    "print(f\"Count BC not GNN: {c_acc_bayes_not_gnn}; \"\n",
    "      f\"GNN not BC: {c_acc_gnn_not_bayes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 205, 4: 183, 5: 180, 2: 149, 6: 103, 1: 69, 7: 55, 8: 28, 0: 11, 9: 11, 10: 3, 11: 2, 12: 1})\n"
     ]
    }
   ],
   "source": [
    "print(c_degree_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(A_[:,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4e45668083cbb37b7048c0587d1e2fbbeab0bbf8f83b3643c89a090a0af4084"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
